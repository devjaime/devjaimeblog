---
layout: "../../layouts/BlogLayout.astro"
title: "Enhancing SQL Query Generation with Large Language Models (LLMs): My Learning Journey"
description: ""
tags: ["code", "SQL", "LLMs"]
time: 4
featured: true
timestamp: "2024-08-16T12:20:32-0300"
filename: "2024-08-16_Enhancing-SQL-Query-Generation-with-Large-Language-Models--LLMs---My-Learning-Journey-81f116646314"
---

Enhancing SQL Query Generation with Large Language Models (LLMs): My Learning Journey
=====================================================================================

In the realm of AI and data science, SQL is an essential tool for extracting valuable insights from databases. As I explored new horizons‚Ä¶

* * *

### Enhancing SQL Query Generation with Large Language Models (LLMs): My Learning¬†Journey

![](https://cdn-images-1.medium.com/max/800/1*Ee61cxklX1GAGpU0Oo8cdQ.png)

In the realm of AI and data science, SQL is an essential tool for extracting valuable insights from databases. As I explored new horizons in this field, I recently completed a course that taught me how to leverage Large Language Models (LLMs), specifically Meta-Llama-3‚Äì8B-Instruct, to generate, fine-tune, and validate SQL queries. This experience not only deepened my understanding of AI‚Äôs potential in query automation but also highlighted the power of prompt engineering and fine-tuning to achieve better results. Here‚Äôs a breakdown of what I learned, including practical examples and how CodeIA.cl can help businesses adopt these technologies.

### Generating SQL Queries with¬†LLMs

One of the core concepts I explored was using LLMs to generate SQL queries based on provided schemas and example queries. By crafting customized prompts, I was able to instruct the model to generate relevant SQL queries in response to specific questions, such as ‚ÄúWhat is the average weight in the NBA?‚Äù

### Example in¬†Python:

from dotenv import load\_dotenv  
import lamini  
from util.get\_schema import get\_schema  
from util.make\_llama\_3\_prompt import make\_llama\_3\_prompt  
load\_dotenv()   \# Load environment variables  
llm = lamini.Lamini(model\_name="meta-llama/Meta-Llama-3-8B-Instruct")  
\# Define the schema and the question  
system = f"""You are an NBA analyst with 15 years of experience writing complex SQL queries.  
Consider the nba\_roster table with the following schema:  
{get\_schema()}"""  
question = "What is the average weight in the NBA?"  
prompt = make\_llama\_3\_prompt(question, system)  
\# Generate the SQL query  
result = llm.generate(prompt, output\_type={"sqlite\_query": "str"}, max\_new\_tokens=200)  
print(result\['sqlite\_query'\])

In this example, the model generates an SQL query based on the schema of an NBA roster and the provided question. This type of automation can significantly speed up data extraction tasks, making it easier for analysts to focus on insights rather than writing complex queries manually.

### Validating and Correcting SQL¬†Queries

Once the LLM generated SQL queries, the next step was validation. By running the queries on a SQLite database, I could determine whether the queries were syntactically correct and returned meaningful results. If the query was incorrect, the model reflected on it to generate a corrected version.

### Example in¬†Python:

import sqlite3  
import pandas as pd  
\# Validate the generated SQL query  
engine = sqlite3.connect("./nba\_roster.db")  
try:  
    df = pd.read\_sql(result\['sqlite\_query'\], con=engine)  
    print(df)  
except Exception as e:  
    print(f"Error in query: {e}")

This process ensures that the queries generated by the model are not only syntactically correct but also return meaningful results. Automating this validation can help reduce errors and improve the efficiency of data teams.

### Fine-Tuning the¬†Model

One of the most exciting parts of the course was learning how to fine-tune the LLM to improve its performance in SQL query generation. Fine-tuning involved training the model with a custom dataset that included specific questions and their corresponding correct SQL queries. This process allowed the model to adapt to the particular nuances of SQL queries and improve its ability to generate accurate results.

At **CodeIA.cl**, we can help businesses customize LLMs to their specific data needs. Whether it‚Äôs training models to generate SQL queries, optimize data pipelines, or automate complex workflows, our expertise in AI can accelerate the development of tailored solutions that meet your unique business challenges.

### Evaluating Model Performance

Evaluation is crucial when working with AI models. In this course, I learned how to evaluate the LLM‚Äôs performance by comparing its generated queries to a reference dataset (gold standard). This evaluation process helps in identifying areas where the model needs further improvement.

### Example of Evaluation:

\# Example of evaluation - comparing generated SQL with reference SQL  
reference\_sql = "SELECT ... (your gold standard query)"  
try:  
    ref\_df = pd.read\_sql(reference\_sql, con=engine)  
    print(ref\_df)  
except Exception as e:  
    print(f"Error in reference query: {e}")

At **CodeIA.cl**, we ensure that AI models perform optimally through rigorous testing and evaluation. We offer services to fine-tune models, compare their outputs with gold-standard datasets, and implement continuous learning systems to keep models up-to-date with evolving data needs.

### Filtering and Cleaning the¬†Dataset

To ensure the quality of the dataset used for fine-tuning and evaluation, I applied filtering techniques to remove invalid queries, queries that returned empty results, or queries that contained errors. This step was crucial for maintaining the integrity of the training data and ensuring that the model learned from accurate and relevant examples.

### How CodeIA.cl Can Support Your¬†Business

At **CodeIA.cl**, we specialize in helping businesses harness the power of AI and LLMs to solve complex challenges. Our services include:

*   **Custom Model Development:** We develop and fine-tune AI models tailored to your specific needs, whether it‚Äôs SQL query automation, natural language processing, or other data-driven tasks.
*   **Data Pipeline Optimization:** We streamline and automate data workflows, ensuring that your data operations are efficient and error-free.
*   **Continuous AI Support:** We provide ongoing support to ensure that your AI models stay relevant as your business and data needs evolve.

By partnering with **CodeIA.cl**, you can leverage cutting-edge AI technology to optimize your operations, reduce manual work, and unlock new opportunities for innovation.

### Conclusion

This course was a transformative experience that expanded my knowledge of how LLMs can be used to automate and optimize SQL query generation. By mastering the process of generating, validating, fine-tuning, and evaluating SQL queries with LLMs, I gained a deeper understanding of how AI can streamline data extraction tasks and improve accuracy in database management.

At **CodeIA.cl**, we are ready to help your business adopt these advanced AI technologies. Whether you‚Äôre looking to automate SQL queries, optimize your data pipelines, or explore other AI-driven solutions, we have the expertise to guide you through the journey.

If you‚Äôre interested in learning more about how **CodeIA.cl** can help your business, feel free to reach out. Let‚Äôs co-create innovative AI solutions together! üöÄ

#AI #SQL #MachineLearning #DataScience #FineTuning #LLM #MetaLlama #CodeIA

By [Jaime Hern√°ndez](https://medium.com/@devjaime) on [August 16, 2024](https://medium.com/p/81f116646314).

[Canonical link](https://medium.com/@devjaime/enhancing-sql-query-generation-with-large-language-models-llms-my-learning-journey-81f116646314)

Exported from [Medium](https://medium.com) on March 15, 2025.