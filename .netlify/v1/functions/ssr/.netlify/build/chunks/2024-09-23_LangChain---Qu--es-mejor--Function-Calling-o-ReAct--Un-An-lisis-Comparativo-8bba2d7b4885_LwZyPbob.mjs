/* empty css                                                                    */
import { d as createComponent, i as renderComponent, r as renderTemplate, u as unescapeHTML } from './astro/server_C7nAViGe.mjs';
import 'kleur/colors';
import { $ as $$BlogLayout } from './BlogLayout_COI89YL8.mjs';

const html = () => "<h1 id=\"langchain-qué-es-mejor-function-calling-o-react-un-análisis-comparativo\">LangChain: ¿Qué es mejor, Function Calling o ReAct? Un Análisis Comparativo</h1>\n<p>LangChain es una herramienta popular en el mundo del desarrollo de aplicaciones basadas en modelos de lenguaje (LLMs), permitiendo la…</p>\n<hr>\n<h3 id=\"langchain-qué-es-mejor-function-calling-o-react-un-análisis-comparativo-1\">LangChain: ¿Qué es mejor, Function Calling o ReAct? Un Análisis Comparativo</h3>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*h76cunDRDO_N0s-cPjVt5A.png\" alt=\"\"></p>\n<p>LangChain es una herramienta popular en el mundo del desarrollo de aplicaciones basadas en modelos de lenguaje (LLMs), permitiendo la integración fluida de estos modelos con herramientas externas como bases de datos, APIs, y otras funciones programáticas. Al construir soluciones avanzadas de IA, dos de las estrategias más comunes para que los LLMs interactúen con herramientas externas son <strong>Function Calling</strong> y <strong>ReAct (Reasoning + Action)</strong>. Cada enfoque tiene sus propias ventajas y desventajas dependiendo del contexto. En este artículo analizaremos cuál es mejor según el caso de uso, con ejemplos claros y un análisis detallado.</p>\n<h3 id=\"qué-es-function-calling-en-langchain\">¿Qué es Function Calling en LangChain?</h3>\n<p><strong>Function Calling</strong> es una característica introducida recientemente en modelos de OpenAI como GPT-4, que permite que el LLM invoque funciones programáticas directamente. Esto significa que el modelo puede decidir cuándo necesita usar una función específica para obtener información o realizar una acción. Es útil cuando deseas que el modelo acceda a una API o a una función externa sin necesidad de intervención manual.</p>\n<h4 id=\"ejemplo-de-function-calling-en-langchain\">Ejemplo de Function Calling en LangChain:</h4>\n<p>from langchain.llms import OpenAI<br>\nfrom langchain.prompts import PromptTemplate<br>\nfrom langchain.chains import LLMChain<br>\n# Definir la función<br>\ndef obtener_precio_cripto(criptomoneda):<br>\nprecios = {“BTC”: 26000, “ETH”: 1800, “ADA”: 0.25}<br>\nreturn precios.get(criptomoneda.upper(), “Criptomoneda no soportada”)<br>\n# Configurar el modelo<br>\nllm = OpenAI(model=“gpt-4”)<br>\n# Definir la plantilla de prompt<br>\nprompt_template = PromptTemplate(<br>\ninput_variables=[“criptomoneda”],<br>\ntemplate=“¿Cuál es el precio actual de {criptomoneda}?”<br>\n)<br>\n# Crear la cadena que llamará la función<br>\nchain = LLMChain(llm=llm, prompt=prompt_template, function=obtener_precio_cripto)<br>\n# Ejecutar el modelo<br>\nrespuesta = chain.run(criptomoneda=“BTC”)<br>\nprint(respuesta)</p>\n<p>En este ejemplo, cuando el modelo recibe una pregunta sobre el precio de una criptomoneda, llama a la función <code>obtener_precio_cripto</code> para obtener la información correcta.</p>\n<h3 id=\"qué-es-react-reasoning-action\">¿Qué es ReAct (Reasoning + Action)?</h3>\n<p><strong>ReAct</strong>, o <em>Reasoning + Acting</em>, es una técnica en la que el modelo primero razona sobre una pregunta o tarea y luego toma acciones basadas en ese razonamiento. Este enfoque es ideal para escenarios más complejos donde el LLM debe pensar antes de actuar, y donde se necesita una secuencia de acciones intermedias. Aquí, el modelo no solo accede a herramientas, sino que genera una “cadena de pensamientos” para justificar su acción.</p>\n<h4 id=\"ejemplo-de-react-en-langchain\">Ejemplo de ReAct en LangChain:</h4>\n<p>from langchain.llms import OpenAI<br>\nfrom langchain.prompts import PromptTemplate<br>\nfrom langchain.agents import Tool, initialize_agent<br>\n# Definir la herramienta<br>\ndef buscar_datos_wikipedia(query):<br>\n# Simulación de búsqueda en Wikipedia<br>\nreturn f”Resultados simulados de Wikipedia sobre {query}“<br>\nherramienta_wikipedia = Tool(name=“Wikipedia”, func=buscar_datos_wikipedia)<br>\n# Configurar el agente y el modelo<br>\nllm = OpenAI(model=“gpt-4”)<br>\nagent = initialize_agent([herramienta_wikipedia], llm, agent_type=“react”)<br>\n# Ejecutar el agente con razonamiento y acción<br>\nrespuesta = agent.run(“¿Quién inventó el avión?“)<br>\nprint(respuesta)</p>\n<p>En este ejemplo, el modelo primero realiza un razonamiento (es decir, reflexiona sobre la pregunta), y luego toma una acción adecuada: usar la herramienta de Wikipedia para buscar la respuesta.</p>\n<h3 id=\"comparativa-function-calling-oreact\">Comparativa: ¿Function Calling o ReAct?</h3>\n<h4 id=\"1-simplicidad-vs-flexibilidad\">1. Simplicidad vs. Flexibilidad:</h4>\n<ul>\n<li><strong>Function Calling</strong> es más simple de implementar en casos donde la acción requerida es directa, como hacer una llamada API o realizar una consulta.</li>\n<li><strong>ReAct</strong> es más flexible cuando el modelo necesita realizar un razonamiento intermedio antes de tomar una acción, por ejemplo, decidir cuál herramienta usar o cómo dividir una tarea compleja en subproblemas.</li>\n</ul>\n<h4 id=\"2-velocidad\">2. Velocidad:</h4>\n<ul>\n<li><strong>Function Calling</strong> es más rápido en la mayoría de los casos. Como el modelo sabe exactamente cuándo y qué función llamar, las interacciones son más rápidas.</li>\n<li><strong>ReAct</strong> puede ser más lento, ya que implica que el modelo “piense” antes de actuar, lo cual puede introducir latencia.</li>\n</ul>\n<h4 id=\"3-escalabilidad\">3. Escalabilidad:</h4>\n<ul>\n<li><strong>Function Calling</strong> es escalable en sistemas con muchas funciones disponibles. Cada función tiene una tarea específica y el modelo puede invocarlas de manera eficiente sin un razonamiento extenso.</li>\n<li><strong>ReAct</strong> es más escalable en escenarios de alta incertidumbre o donde se requiere flexibilidad en el proceso de toma de decisiones.</li>\n</ul>\n<h4 id=\"4-casos-de-usoideales\">4. Casos de uso ideales:</h4>\n<ul>\n<li><strong>Function Calling</strong>: Ideal para tareas directas, como consultas de datos, cálculos o integración de APIs bien definidas (e.g., obtener datos de un sensor).</li>\n<li><strong>ReAct</strong>: Ideal para tareas que requieren una secuencia de decisiones o razonamiento complejo (e.g., resolver problemas de diagnóstico, responder a preguntas abiertas que involucran múltiples fuentes).</li>\n</ul>\n<h3 id=\"conclusión-cuál-deberíasusar\">Conclusión: ¿Cuál deberías usar?</h3>\n<p>La elección entre <strong>Function Calling</strong> y <strong>ReAct</strong> depende principalmente de la <strong>complejidad de la tarea</strong> y la <strong>necesidad de razonamiento</strong>:</p>\n<ul>\n<li>Si tu tarea es sencilla y directa, como llamar a una API o ejecutar una función específica, <strong>Function Calling</strong> será la opción más eficiente.</li>\n<li>Si la tarea requiere múltiples pasos, un razonamiento intermedio o decisiones complejas, <strong>ReAct</strong> proporcionará la flexibilidad necesaria para abordar esas situaciones.</li>\n</ul>\n<p>Ambas estrategias son poderosas y, a menudo, complementarias en el desarrollo de soluciones avanzadas con LangChain. Combinar ambos enfoques puede ser la clave para lograr aplicaciones de IA robustas, que no solo ejecuten acciones precisas, sino que también sean capaces de adaptarse a escenarios complejos y desafiantes.</p>\n<hr>\n<p>Este análisis cubre los conceptos clave de Function Calling y ReAct en LangChain, proporcionándote ejemplos claros y prácticos para que puedas integrarlos en tus proyectos. ¿Tienes alguna preferencia o experiencia utilizando alguna de estas técnicas? ¡Deja tus comentarios y comparte tus ideas!</p>\n<hr>\n<p><strong>Referencias</strong>:</p>\n<ul>\n<li>LangChain Documentation (<a href=\"https://python.langchain.com\">https://python.langchain.com</a>)</li>\n<li>OpenAI GPT-4: Function Calling (<a href=\"https://openai.com/index/function-calling-and-other-api-updates/\">https://openai.com/index/function-calling-and-other-api-updates/</a>)</li>\n</ul>\n<p>By <a href=\"https://medium.com/@devjaime\">Jaime Hernández</a> on <a href=\"https://medium.com/p/8bba2d7b4885\">September 23, 2024</a>.</p>\n<p><a href=\"https://medium.com/@devjaime/langchain-qu%C3%A9-es-mejor-function-calling-o-react-un-an%C3%A1lisis-comparativo-8bba2d7b4885\">Canonical link</a></p>\n<p>Exported from <a href=\"https://medium.com\">Medium</a> on March 15, 2025.</p>";

				const frontmatter = {"layout":"../../layouts/BlogLayout.astro","title":"LangChain: ¿Qué es mejor, Function Calling o ReAct? Un Análisis Comparativo","description":"","tags":["code","Langchain"],"time":4,"featured":true,"timestamp":"2024-09-23T12:20:32-0300","filename":"2024-09-23_LangChain---Qu--es-mejor--Function-Calling-o-ReAct--Un-An-lisis-Comparativo-8bba2d7b4885"};
				const file = "/Users/devjaime/Documents/devjaimeblog/src/pages/blog/2024-09-23_LangChain---Qu--es-mejor--Function-Calling-o-ReAct--Un-An-lisis-Comparativo-8bba2d7b4885.md";
				const url = "/blog/2024-09-23_LangChain---Qu--es-mejor--Function-Calling-o-ReAct--Un-An-lisis-Comparativo-8bba2d7b4885";
				function rawContent() {
					return "   \n                                        \n                                                                                    \n               \n                           \n       \n              \n                                     \n                                                                                                               \n   \n\nLangChain: ¿Qué es mejor, Function Calling o ReAct? Un Análisis Comparativo\n===========================================================================\n\nLangChain es una herramienta popular en el mundo del desarrollo de aplicaciones basadas en modelos de lenguaje (LLMs), permitiendo la…\n\n* * *\n\n### LangChain: ¿Qué es mejor, Function Calling o ReAct? Un Análisis Comparativo\n\n![](https://cdn-images-1.medium.com/max/800/1*h76cunDRDO_N0s-cPjVt5A.png)\n\nLangChain es una herramienta popular en el mundo del desarrollo de aplicaciones basadas en modelos de lenguaje (LLMs), permitiendo la integración fluida de estos modelos con herramientas externas como bases de datos, APIs, y otras funciones programáticas. Al construir soluciones avanzadas de IA, dos de las estrategias más comunes para que los LLMs interactúen con herramientas externas son **Function Calling** y **ReAct (Reasoning + Action)**. Cada enfoque tiene sus propias ventajas y desventajas dependiendo del contexto. En este artículo analizaremos cuál es mejor según el caso de uso, con ejemplos claros y un análisis detallado.\n\n### ¿Qué es Function Calling en LangChain?\n\n**Function Calling** es una característica introducida recientemente en modelos de OpenAI como GPT-4, que permite que el LLM invoque funciones programáticas directamente. Esto significa que el modelo puede decidir cuándo necesita usar una función específica para obtener información o realizar una acción. Es útil cuando deseas que el modelo acceda a una API o a una función externa sin necesidad de intervención manual.\n\n#### Ejemplo de Function Calling en LangChain:\n\nfrom langchain.llms import OpenAI  \nfrom langchain.prompts import PromptTemplate  \nfrom langchain.chains import LLMChain  \n\\# Definir la función  \ndef obtener\\_precio\\_cripto(criptomoneda):  \n    precios = {\"BTC\": 26000, \"ETH\": 1800, \"ADA\": 0.25}  \n    return precios.get(criptomoneda.upper(), \"Criptomoneda no soportada\")  \n\\# Configurar el modelo  \nllm = OpenAI(model=\"gpt-4\")  \n\\# Definir la plantilla de prompt  \nprompt\\_template = PromptTemplate(  \n    input\\_variables=\\[\"criptomoneda\"\\],  \n    template=\"¿Cuál es el precio actual de {criptomoneda}?\"  \n)  \n\\# Crear la cadena que llamará la función  \nchain = LLMChain(llm=llm, prompt=prompt\\_template, function=obtener\\_precio\\_cripto)  \n\\# Ejecutar el modelo  \nrespuesta = chain.run(criptomoneda=\"BTC\")  \nprint(respuesta)\n\nEn este ejemplo, cuando el modelo recibe una pregunta sobre el precio de una criptomoneda, llama a la función `obtener_precio_cripto` para obtener la información correcta.\n\n### ¿Qué es ReAct (Reasoning + Action)?\n\n**ReAct**, o _Reasoning + Acting_, es una técnica en la que el modelo primero razona sobre una pregunta o tarea y luego toma acciones basadas en ese razonamiento. Este enfoque es ideal para escenarios más complejos donde el LLM debe pensar antes de actuar, y donde se necesita una secuencia de acciones intermedias. Aquí, el modelo no solo accede a herramientas, sino que genera una “cadena de pensamientos” para justificar su acción.\n\n#### Ejemplo de ReAct en LangChain:\n\nfrom langchain.llms import OpenAI  \nfrom langchain.prompts import PromptTemplate  \nfrom langchain.agents import Tool, initialize\\_agent  \n\\# Definir la herramienta  \ndef buscar\\_datos\\_wikipedia(query):  \n    \\# Simulación de búsqueda en Wikipedia  \n    return f\"Resultados simulados de Wikipedia sobre {query}\"  \nherramienta\\_wikipedia = Tool(name=\"Wikipedia\", func=buscar\\_datos\\_wikipedia)  \n\\# Configurar el agente y el modelo  \nllm = OpenAI(model=\"gpt-4\")  \nagent = initialize\\_agent(\\[herramienta\\_wikipedia\\], llm, agent\\_type=\"react\")  \n\\# Ejecutar el agente con razonamiento y acción  \nrespuesta = agent.run(\"¿Quién inventó el avión?\")  \nprint(respuesta)\n\nEn este ejemplo, el modelo primero realiza un razonamiento (es decir, reflexiona sobre la pregunta), y luego toma una acción adecuada: usar la herramienta de Wikipedia para buscar la respuesta.\n\n### Comparativa: ¿Function Calling o ReAct?\n\n#### 1\\. Simplicidad vs. Flexibilidad:\n\n*   **Function Calling** es más simple de implementar en casos donde la acción requerida es directa, como hacer una llamada API o realizar una consulta.\n*   **ReAct** es más flexible cuando el modelo necesita realizar un razonamiento intermedio antes de tomar una acción, por ejemplo, decidir cuál herramienta usar o cómo dividir una tarea compleja en subproblemas.\n\n#### 2\\. Velocidad:\n\n*   **Function Calling** es más rápido en la mayoría de los casos. Como el modelo sabe exactamente cuándo y qué función llamar, las interacciones son más rápidas.\n*   **ReAct** puede ser más lento, ya que implica que el modelo “piense” antes de actuar, lo cual puede introducir latencia.\n\n#### 3\\. Escalabilidad:\n\n*   **Function Calling** es escalable en sistemas con muchas funciones disponibles. Cada función tiene una tarea específica y el modelo puede invocarlas de manera eficiente sin un razonamiento extenso.\n*   **ReAct** es más escalable en escenarios de alta incertidumbre o donde se requiere flexibilidad en el proceso de toma de decisiones.\n\n#### 4\\. Casos de uso ideales:\n\n*   **Function Calling**: Ideal para tareas directas, como consultas de datos, cálculos o integración de APIs bien definidas (e.g., obtener datos de un sensor).\n*   **ReAct**: Ideal para tareas que requieren una secuencia de decisiones o razonamiento complejo (e.g., resolver problemas de diagnóstico, responder a preguntas abiertas que involucran múltiples fuentes).\n\n### Conclusión: ¿Cuál deberías usar?\n\nLa elección entre **Function Calling** y **ReAct** depende principalmente de la **complejidad de la tarea** y la **necesidad de razonamiento**:\n\n*   Si tu tarea es sencilla y directa, como llamar a una API o ejecutar una función específica, **Function Calling** será la opción más eficiente.\n*   Si la tarea requiere múltiples pasos, un razonamiento intermedio o decisiones complejas, **ReAct** proporcionará la flexibilidad necesaria para abordar esas situaciones.\n\nAmbas estrategias son poderosas y, a menudo, complementarias en el desarrollo de soluciones avanzadas con LangChain. Combinar ambos enfoques puede ser la clave para lograr aplicaciones de IA robustas, que no solo ejecuten acciones precisas, sino que también sean capaces de adaptarse a escenarios complejos y desafiantes.\n\n* * *\n\nEste análisis cubre los conceptos clave de Function Calling y ReAct en LangChain, proporcionándote ejemplos claros y prácticos para que puedas integrarlos en tus proyectos. ¿Tienes alguna preferencia o experiencia utilizando alguna de estas técnicas? ¡Deja tus comentarios y comparte tus ideas!\n\n* * *\n\n**Referencias**:\n\n*   LangChain Documentation (https://python.langchain.com)\n*   OpenAI GPT-4: Function Calling ([https://openai.com/index/function-calling-and-other-api-updates/](https://openai.com/index/function-calling-and-other-api-updates/))\n\nBy [Jaime Hernández](https://medium.com/@devjaime) on [September 23, 2024](https://medium.com/p/8bba2d7b4885).\n\n[Canonical link](https://medium.com/@devjaime/langchain-qu%C3%A9-es-mejor-function-calling-o-react-un-an%C3%A1lisis-comparativo-8bba2d7b4885)\n\nExported from [Medium](https://medium.com) on March 15, 2025.";
				}
				async function compiledContent() {
					return await html();
				}
				function getHeadings() {
					return [{"depth":1,"slug":"langchain-qué-es-mejor-function-calling-o-react-un-análisis-comparativo","text":"LangChain: ¿Qué es mejor, Function Calling o ReAct? Un Análisis Comparativo"},{"depth":3,"slug":"langchain-qué-es-mejor-function-calling-o-react-un-análisis-comparativo-1","text":"LangChain: ¿Qué es mejor, Function Calling o ReAct? Un Análisis Comparativo"},{"depth":3,"slug":"qué-es-function-calling-en-langchain","text":"¿Qué es Function Calling en LangChain?"},{"depth":4,"slug":"ejemplo-de-function-calling-en-langchain","text":"Ejemplo de Function Calling en LangChain:"},{"depth":3,"slug":"qué-es-react-reasoning-action","text":"¿Qué es ReAct (Reasoning + Action)?"},{"depth":4,"slug":"ejemplo-de-react-en-langchain","text":"Ejemplo de ReAct en LangChain:"},{"depth":3,"slug":"comparativa-function-calling-oreact","text":"Comparativa: ¿Function Calling o ReAct?"},{"depth":4,"slug":"1-simplicidad-vs-flexibilidad","text":"1. Simplicidad vs. Flexibilidad:"},{"depth":4,"slug":"2-velocidad","text":"2. Velocidad:"},{"depth":4,"slug":"3-escalabilidad","text":"3. Escalabilidad:"},{"depth":4,"slug":"4-casos-de-usoideales","text":"4. Casos de uso ideales:"},{"depth":3,"slug":"conclusión-cuál-deberíasusar","text":"Conclusión: ¿Cuál deberías usar?"}];
				}

				const Content = createComponent((result, _props, slots) => {
					const { layout, ...content } = frontmatter;
					content.file = file;
					content.url = url;

					return renderTemplate`${renderComponent(result, 'Layout', $$BlogLayout, {
								file,
								url,
								content,
								frontmatter: content,
								headings: getHeadings(),
								rawContent,
								compiledContent,
								'server:root': true,
							}, {
								'default': () => renderTemplate`${unescapeHTML(html())}`
							})}`;
				});

const _page = /*#__PURE__*/Object.freeze(/*#__PURE__*/Object.defineProperty({
	__proto__: null,
	Content,
	compiledContent,
	default: Content,
	file,
	frontmatter,
	getHeadings,
	rawContent,
	url
}, Symbol.toStringTag, { value: 'Module' }));

export { _page as _ };
