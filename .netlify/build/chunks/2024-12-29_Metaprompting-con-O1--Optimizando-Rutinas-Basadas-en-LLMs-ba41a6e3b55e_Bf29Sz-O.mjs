/* empty css                                                                    */
import { d as createComponent, i as renderComponent, r as renderTemplate, u as unescapeHTML } from './astro/server_C7nAViGe.mjs';
import 'kleur/colors';
import { $ as $$BlogLayout } from './BlogLayout_COI89YL8.mjs';

const html = () => "<h1 id=\"metaprompting-con-o1-optimizando-rutinas-basadas-en-llms\">Metaprompting con O1: Optimizando Rutinas Basadas en LLMs</h1>\n<p>En este artículo exploraremos cómo usar el modelo O1-mini para generar y mejorar rutinas basadas en modelos de lenguaje grande (LLMs). Este…</p>\n<hr>\n<h3 id=\"metaprompting-con-o1-optimizando-rutinas-basadas-enllms\">Metaprompting con O1: Optimizando Rutinas Basadas en LLMs</h3>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*ZhPuzDOsd4h8hM-dUD7H6w.png\" alt=\"\"></p>\n<p><a href=\"https://www.kdnuggets.com/getting-started-with-openai-o1-reasoning-models\">https://www.kdnuggets.com/getting-started-with-openai-o1-reasoning-models</a></p>\n<p>En este artículo exploraremos cómo usar el modelo <strong>O1-mini</strong> para generar y mejorar rutinas basadas en modelos de lenguaje grande (LLMs). Este enfoque permite optimizar tareas como la generación de políticas de servicio al cliente, el ajuste de instrucciones y la evaluación iterativa para mejorar resultados en contextos dinámicos.</p>\n<hr>\n<h3 id=\"introducción-a-metaprompting\">Introducción a Metaprompting</h3>\n<p>El metaprompting consiste en el uso de un modelo de lenguaje para analizar y mejorar iterativamente un conjunto de instrucciones o políticas, utilizando evaluaciones previas como guía. Esta técnica es particularmente útil cuando se trabaja con rutinas de alta complejidad, como políticas de cancelación de vuelos, donde múltiples herramientas y pasos deben coordinarse eficientemente.</p>\n<h3 id=\"por-qué-usaro1\">¿Por qué usar O1?</h3>\n<ul>\n<li><strong>Optimización iterativa:</strong> Permite ajustar rutinas basadas en evaluaciones previas.</li>\n<li><strong>Compatibilidad:</strong> Diseñado para trabajar con herramientas específicas definidas por el usuario.</li>\n<li><strong>Flexibilidad:</strong> Admite cambios en el formato y enfoque de las instrucciones.</li>\n</ul>\n<hr>\n<h3 id=\"caso-práctico-política-de-cancelación-devuelos\">Caso Práctico: Política de Cancelación de Vuelos</h3>\n<h3 id=\"paso-1-generar-larutina\">Paso 1: Generar la Rutina</h3>\n<p>Comenzamos con una política de servicio al cliente escrita en texto plano y la convertimos en una rutina estructurada usando O1-mini.</p>\n<h4 id=\"código-para-generar-larutina\">Código para Generar la Rutina</h4>\n<p>from openai import OpenAI<br>\nclient = OpenAI(api_key=openai_api_key)<br>\nCONVERSION_PROMPT = \"\"\"<br>\nYou are a helpful assistant tasked with taking an external-facing help center policy and converting it into a structured routine.<br>\n… (instrucciones detalladas para el formato y condiciones específicas)<br>\n\"\"\"<br>\nwith open(‘originalPolicy/flightCancellationsPolicy.md’, ‘r’) as file:<br>\nflight_cancellation_policy = file.read()<br>\nmessages = [<br>\n{<br>\n“role”: “user”,<br>\n“content”: f\"\"\"{CONVERSION_PROMPT}\\nPOLICY:\\n{flight_cancellation_policy}\"\"\"<br>\n}<br>\n]<br>\nresponse = client.chat.completions.create(<br>\nmodel=‘o1-mini’,<br>\nmessages=messages<br>\n)<br>\nprint(response.choices[0].message.content)</p>\n<p>El resultado es una rutina en formato estructurado que incluye pasos numerados, subpasos y condiciones específicas.</p>\n<hr>\n<h3 id=\"paso-2-verificar-la-calidad-de-larutina\">Paso 2: Verificar la Calidad de la Rutina</h3>\n<p>Una vez generada, verificamos que la rutina utilice exclusivamente las herramientas definidas en nuestra lista de <code>TOOLS</code>.</p>\n<h4 id=\"código-para-verificación\">Código para Verificación</h4>\n<p>import re<br>\nfrom collections import Counter<br>\ndef extract_function_names(text):<br>\npattern = r’`(.*?)`‘<br>\nreturn re.findall(pattern, text)<br>\n# Funciones utilizadas en la rutina<br>\nfunction_names_from_routine = set(extract_function_names(response.choices[0].message.content))<br>\n# Funciones definidas en TOOLS<br>\nfunction_names_defined = [tool[“function”][“name”] for tool in TOOLS]<br>\n# Diferencias<br>\nunused_functions = set(function_names_defined) - function_names_from_routine<br>\nextra_functions = function_names_from_routine - set(function_names_defined)<br>\nprint(“Funciones no utilizadas:”, unused_functions)<br>\nprint(“Funciones adicionales requeridas:”, extra_functions)</p>\n<p>Este proceso asegura que la rutina generada esté alineada con las herramientas disponibles.</p>\n<hr>\n<h3 id=\"paso-3-evaluar-y-mejorar-larutina\">Paso 3: Evaluar y Mejorar la Rutina</h3>\n<h4 id=\"evaluación\">Evaluación</h4>\n<p>Corremos la rutina contra un conjunto de datos de prueba para medir su precisión y determinar áreas de mejora.</p>\n<h4 id=\"código-para-evaluación\">Código para Evaluación</h4>\n<p>from concurrent.futures import ThreadPoolExecutor<br>\nimport pandas as pd<br>\n# Evaluar llamadas a funciones<br>\ndef evaluate_function_calls(df, policy, model):<br>\nrecords = []<br>\nwith ThreadPoolExecutor() as executor:<br>\nfutures = {executor.submit(process_row, row_number, row, policy, model): row_number for row_number, row in df.iterrows()}<br>\nfor future in futures:<br>\nrecords.append(future.result())<br>\neval_df = pd.DataFrame(records)<br>\naccuracy = eval_df[‘is_correct’].mean()<br>\nreturn eval_df, accuracy<br>\n# Resultados iniciales<br>\neval_df = pd.read_csv(‘evals/policyEvals.csv’)<br>\neval_results, initial_accuracy = evaluate_function_calls(eval_df, flight_cancellation_policy, ‘gpt-4o-mini’)<br>\nprint(“Precisión inicial:”, initial_accuracy)</p>\n<h4 id=\"mejora-de-larutina\">Mejora de la Rutina</h4>\n<p>Iteramos sobre la rutina usando un bucle de metaprompting para incorporar cambios basados en los resultados de evaluación.</p>\n<p>for i in range(3):<br>\nmessages = [<br>\n{<br>\n“role”: “user”,<br>\n“content”: f\"\"\"# Data\\nRoutine: {current_routine}\\nResults: {eval_results.to_json()}\"\"\"<br>\n}<br>\n]</p>\n<p>response = client.chat.completions.create(<br>\nmodel=‘o1-mini’,<br>\nmessages=messages<br>\n)<br>\nupdated_routine = response.choices[0].message.content<br>\ncurrent_routine = updated_routine<br>\neval_results, accuracy = evaluate_function_calls(eval_df, current_routine, ‘gpt-4o-mini’)<br>\nprint(f”Iteración {i+1}, Precisión: {accuracy}”)</p>\n<p>El objetivo es maximizar la precisión del modelo mientras se mantiene la consistencia con la política original.</p>\n<hr>\n<h3 id=\"conclusión\">Conclusión</h3>\n<p>El metaprompting con O1 es una herramienta poderosa para optimizar rutinas basadas en LLMs. Desde la generación inicial hasta la mejora iterativa, este enfoque asegura que las rutinas sean precisas, consistentes y adaptadas a herramientas específicas.</p>\n<h3 id=\"recursos-relacionados\">Recursos Relacionados</h3>\n<ul>\n<li><a href=\"https://platform.openai.com/docs/\">Documentación de O1</a></li>\n<li><a href=\"https://cookbook.openai.com/examples/o1/using_reasoning_for_routine_generation\">Cookbook de O1</a></li>\n</ul>\n<p>By <a href=\"https://medium.com/@devjaime\">Jaime Hernández</a> on <a href=\"https://medium.com/p/ba41a6e3b55e\">December 29, 2024</a>.</p>\n<p><a href=\"https://medium.com/@devjaime/metaprompting-con-o1-optimizando-rutinas-basadas-en-llms-ba41a6e3b55e\">Canonical link</a></p>\n<p>Exported from <a href=\"https://medium.com\">Medium</a> on March 15, 2025.</p>";

				const frontmatter = {"layout":"../../layouts/BlogLayout.astro","title":"Metaprompting con O1: Optimizando Rutinas Basadas en LLMs","description":"","tags":["code","Metaprompting","O1","OpenAI","LLMs"],"time":4,"featured":true,"timestamp":"2024-12-29T12:20:33-0300","filename":"2024-12-29_Metaprompting-con-O1--Optimizando-Rutinas-Basadas-en-LLMs-ba41a6e3b55e"};
				const file = "/Users/devjaime/Documents/devjaimeblog/src/pages/blog/2024-12-29_Metaprompting-con-O1--Optimizando-Rutinas-Basadas-en-LLMs-ba41a6e3b55e.md";
				const url = "/blog/2024-12-29_Metaprompting-con-O1--Optimizando-Rutinas-Basadas-en-LLMs-ba41a6e3b55e";
				function rawContent() {
					return "   \n                                        \n                                                                  \n               \n                                                       \n       \n              \n                                     \n                                                                                             \n   \n\nMetaprompting con O1: Optimizando Rutinas Basadas en LLMs\n=========================================================\n\nEn este artículo exploraremos cómo usar el modelo O1-mini para generar y mejorar rutinas basadas en modelos de lenguaje grande (LLMs). Este…\n\n* * *\n\n### Metaprompting con O1: Optimizando Rutinas Basadas en LLMs\n\n![](https://cdn-images-1.medium.com/max/800/1*ZhPuzDOsd4h8hM-dUD7H6w.png)\n\n[https://www.kdnuggets.com/getting-started-with-openai-o1-reasoning-models](https://www.kdnuggets.com/getting-started-with-openai-o1-reasoning-models)\n\nEn este artículo exploraremos cómo usar el modelo **O1-mini** para generar y mejorar rutinas basadas en modelos de lenguaje grande (LLMs). Este enfoque permite optimizar tareas como la generación de políticas de servicio al cliente, el ajuste de instrucciones y la evaluación iterativa para mejorar resultados en contextos dinámicos.\n\n* * *\n\n### Introducción a Metaprompting\n\nEl metaprompting consiste en el uso de un modelo de lenguaje para analizar y mejorar iterativamente un conjunto de instrucciones o políticas, utilizando evaluaciones previas como guía. Esta técnica es particularmente útil cuando se trabaja con rutinas de alta complejidad, como políticas de cancelación de vuelos, donde múltiples herramientas y pasos deben coordinarse eficientemente.\n\n### ¿Por qué usar O1?\n\n*   **Optimización iterativa:** Permite ajustar rutinas basadas en evaluaciones previas.\n*   **Compatibilidad:** Diseñado para trabajar con herramientas específicas definidas por el usuario.\n*   **Flexibilidad:** Admite cambios en el formato y enfoque de las instrucciones.\n\n* * *\n\n### Caso Práctico: Política de Cancelación de Vuelos\n\n### Paso 1: Generar la Rutina\n\nComenzamos con una política de servicio al cliente escrita en texto plano y la convertimos en una rutina estructurada usando O1-mini.\n\n#### Código para Generar la Rutina\n\nfrom openai import OpenAI  \nclient = OpenAI(api\\_key=openai\\_api\\_key)  \nCONVERSION\\_PROMPT = \"\"\"  \nYou are a helpful assistant tasked with taking an external-facing help center policy and converting it into a structured routine.  \n... (instrucciones detalladas para el formato y condiciones específicas)  \n\"\"\"  \nwith open('originalPolicy/flightCancellationsPolicy.md', 'r') as file:  \n    flight\\_cancellation\\_policy = file.read()  \nmessages = \\[  \n    {  \n        \"role\": \"user\",  \n        \"content\": f\"\"\"{CONVERSION\\_PROMPT}\\\\nPOLICY:\\\\n{flight\\_cancellation\\_policy}\"\"\"  \n    }  \n\\]  \nresponse = client.chat.completions.create(  \n    model='o1-mini',  \n    messages=messages  \n)  \nprint(response.choices\\[0\\].message.content)\n\nEl resultado es una rutina en formato estructurado que incluye pasos numerados, subpasos y condiciones específicas.\n\n* * *\n\n### Paso 2: Verificar la Calidad de la Rutina\n\nUna vez generada, verificamos que la rutina utilice exclusivamente las herramientas definidas en nuestra lista de `TOOLS`.\n\n#### Código para Verificación\n\nimport re  \nfrom collections import Counter  \ndef extract\\_function\\_names(text):  \n    pattern = r'\\`(.\\*?)\\`'  \n    return re.findall(pattern, text)  \n\\# Funciones utilizadas en la rutina  \nfunction\\_names\\_from\\_routine = set(extract\\_function\\_names(response.choices\\[0\\].message.content))  \n\\# Funciones definidas en TOOLS  \nfunction\\_names\\_defined = \\[tool\\[\"function\"\\]\\[\"name\"\\] for tool in TOOLS\\]  \n\\# Diferencias  \nunused\\_functions = set(function\\_names\\_defined) - function\\_names\\_from\\_routine  \nextra\\_functions = function\\_names\\_from\\_routine - set(function\\_names\\_defined)  \nprint(\"Funciones no utilizadas:\", unused\\_functions)  \nprint(\"Funciones adicionales requeridas:\", extra\\_functions)\n\nEste proceso asegura que la rutina generada esté alineada con las herramientas disponibles.\n\n* * *\n\n### Paso 3: Evaluar y Mejorar la Rutina\n\n#### Evaluación\n\nCorremos la rutina contra un conjunto de datos de prueba para medir su precisión y determinar áreas de mejora.\n\n#### Código para Evaluación\n\nfrom concurrent.futures import ThreadPoolExecutor  \nimport pandas as pd  \n\\# Evaluar llamadas a funciones  \ndef evaluate\\_function\\_calls(df, policy, model):  \n    records = \\[\\]  \n    with ThreadPoolExecutor() as executor:  \n        futures = {executor.submit(process\\_row, row\\_number, row, policy, model): row\\_number for row\\_number, row in df.iterrows()}  \n        for future in futures:  \n            records.append(future.result())  \n    eval\\_df = pd.DataFrame(records)  \n    accuracy = eval\\_df\\['is\\_correct'\\].mean()  \n    return eval\\_df, accuracy  \n\\# Resultados iniciales  \neval\\_df = pd.read\\_csv('evals/policyEvals.csv')  \neval\\_results, initial\\_accuracy = evaluate\\_function\\_calls(eval\\_df, flight\\_cancellation\\_policy, 'gpt-4o-mini')  \nprint(\"Precisión inicial:\", initial\\_accuracy)\n\n#### Mejora de la Rutina\n\nIteramos sobre la rutina usando un bucle de metaprompting para incorporar cambios basados en los resultados de evaluación.\n\nfor i in range(3):  \n    messages = \\[  \n        {  \n            \"role\": \"user\",  \n            \"content\": f\"\"\"# Data\\\\nRoutine: {current\\_routine}\\\\nResults: {eval\\_results.to\\_json()}\"\"\"  \n        }  \n    \\]  \n  \nresponse = client.chat.completions.create(  \n        model='o1-mini',  \n        messages=messages  \n    )  \n    updated\\_routine = response.choices\\[0\\].message.content  \n    current\\_routine = updated\\_routine  \n    eval\\_results, accuracy = evaluate\\_function\\_calls(eval\\_df, current\\_routine, 'gpt-4o-mini')  \n    print(f\"Iteración {i+1}, Precisión: {accuracy}\")\n\nEl objetivo es maximizar la precisión del modelo mientras se mantiene la consistencia con la política original.\n\n* * *\n\n### Conclusión\n\nEl metaprompting con O1 es una herramienta poderosa para optimizar rutinas basadas en LLMs. Desde la generación inicial hasta la mejora iterativa, este enfoque asegura que las rutinas sean precisas, consistentes y adaptadas a herramientas específicas.\n\n### Recursos Relacionados\n\n*   [Documentación de O1](https://platform.openai.com/docs/)\n*   [Cookbook de O1](https://cookbook.openai.com/examples/o1/using_reasoning_for_routine_generation)\n\nBy [Jaime Hernández](https://medium.com/@devjaime) on [December 29, 2024](https://medium.com/p/ba41a6e3b55e).\n\n[Canonical link](https://medium.com/@devjaime/metaprompting-con-o1-optimizando-rutinas-basadas-en-llms-ba41a6e3b55e)\n\nExported from [Medium](https://medium.com) on March 15, 2025.";
				}
				async function compiledContent() {
					return await html();
				}
				function getHeadings() {
					return [{"depth":1,"slug":"metaprompting-con-o1-optimizando-rutinas-basadas-en-llms","text":"Metaprompting con O1: Optimizando Rutinas Basadas en LLMs"},{"depth":3,"slug":"metaprompting-con-o1-optimizando-rutinas-basadas-enllms","text":"Metaprompting con O1: Optimizando Rutinas Basadas en LLMs"},{"depth":3,"slug":"introducción-a-metaprompting","text":"Introducción a Metaprompting"},{"depth":3,"slug":"por-qué-usaro1","text":"¿Por qué usar O1?"},{"depth":3,"slug":"caso-práctico-política-de-cancelación-devuelos","text":"Caso Práctico: Política de Cancelación de Vuelos"},{"depth":3,"slug":"paso-1-generar-larutina","text":"Paso 1: Generar la Rutina"},{"depth":4,"slug":"código-para-generar-larutina","text":"Código para Generar la Rutina"},{"depth":3,"slug":"paso-2-verificar-la-calidad-de-larutina","text":"Paso 2: Verificar la Calidad de la Rutina"},{"depth":4,"slug":"código-para-verificación","text":"Código para Verificación"},{"depth":3,"slug":"paso-3-evaluar-y-mejorar-larutina","text":"Paso 3: Evaluar y Mejorar la Rutina"},{"depth":4,"slug":"evaluación","text":"Evaluación"},{"depth":4,"slug":"código-para-evaluación","text":"Código para Evaluación"},{"depth":4,"slug":"mejora-de-larutina","text":"Mejora de la Rutina"},{"depth":3,"slug":"conclusión","text":"Conclusión"},{"depth":3,"slug":"recursos-relacionados","text":"Recursos Relacionados"}];
				}

				const Content = createComponent((result, _props, slots) => {
					const { layout, ...content } = frontmatter;
					content.file = file;
					content.url = url;

					return renderTemplate`${renderComponent(result, 'Layout', $$BlogLayout, {
								file,
								url,
								content,
								frontmatter: content,
								headings: getHeadings(),
								rawContent,
								compiledContent,
								'server:root': true,
							}, {
								'default': () => renderTemplate`${unescapeHTML(html())}`
							})}`;
				});

const _page = /*#__PURE__*/Object.freeze(/*#__PURE__*/Object.defineProperty({
	__proto__: null,
	Content,
	compiledContent,
	default: Content,
	file,
	frontmatter,
	getHeadings,
	rawContent,
	url
}, Symbol.toStringTag, { value: 'Module' }));

export { _page as _ };
