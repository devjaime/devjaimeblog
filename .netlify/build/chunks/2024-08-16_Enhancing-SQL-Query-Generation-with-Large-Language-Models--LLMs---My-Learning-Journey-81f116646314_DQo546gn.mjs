/* empty css                                                                    */
import { d as createComponent, i as renderComponent, r as renderTemplate, u as unescapeHTML } from './astro/server_C7nAViGe.mjs';
import 'kleur/colors';
import { $ as $$BlogLayout } from './BlogLayout_COI89YL8.mjs';

const html = () => "<h1 id=\"enhancing-sql-query-generation-with-large-language-models-llms-my-learning-journey\">Enhancing SQL Query Generation with Large Language Models (LLMs): My Learning Journey</h1>\n<p>In the realm of AI and data science, SQL is an essential tool for extracting valuable insights from databases. As I explored new horizons‚Ä¶</p>\n<hr>\n<h3 id=\"enhancing-sql-query-generation-with-large-language-models-llms-my-learningjourney\">Enhancing SQL Query Generation with Large Language Models (LLMs): My Learning¬†Journey</h3>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*Ee61cxklX1GAGpU0Oo8cdQ.png\" alt=\"\"></p>\n<p>In the realm of AI and data science, SQL is an essential tool for extracting valuable insights from databases. As I explored new horizons in this field, I recently completed a course that taught me how to leverage Large Language Models (LLMs), specifically Meta-Llama-3‚Äì8B-Instruct, to generate, fine-tune, and validate SQL queries. This experience not only deepened my understanding of AI‚Äôs potential in query automation but also highlighted the power of prompt engineering and fine-tuning to achieve better results. Here‚Äôs a breakdown of what I learned, including practical examples and how CodeIA.cl can help businesses adopt these technologies.</p>\n<h3 id=\"generating-sql-queries-withllms\">Generating SQL Queries with¬†LLMs</h3>\n<p>One of the core concepts I explored was using LLMs to generate SQL queries based on provided schemas and example queries. By crafting customized prompts, I was able to instruct the model to generate relevant SQL queries in response to specific questions, such as ‚ÄúWhat is the average weight in the NBA?‚Äù</p>\n<h3 id=\"example-inpython\">Example in¬†Python:</h3>\n<p>from dotenv import load_dotenv<br>\nimport lamini<br>\nfrom util.get_schema import get_schema<br>\nfrom util.make_llama_3_prompt import make_llama_3_prompt<br>\nload_dotenv()   # Load environment variables<br>\nllm = lamini.Lamini(model_name=‚Äúmeta-llama/Meta-Llama-3-8B-Instruct‚Äù)<br>\n# Define the schema and the question<br>\nsystem = f\"\"\"You are an NBA analyst with 15 years of experience writing complex SQL queries.<br>\nConsider the nba_roster table with the following schema:<br>\n{get_schema()}\"\"\"<br>\nquestion = ‚ÄúWhat is the average weight in the NBA?‚Äú<br>\nprompt = make_llama_3_prompt(question, system)<br>\n# Generate the SQL query<br>\nresult = llm.generate(prompt, output_type={‚Äúsqlite_query‚Äù: ‚Äústr‚Äù}, max_new_tokens=200)<br>\nprint(result[‚Äòsqlite_query‚Äô])</p>\n<p>In this example, the model generates an SQL query based on the schema of an NBA roster and the provided question. This type of automation can significantly speed up data extraction tasks, making it easier for analysts to focus on insights rather than writing complex queries manually.</p>\n<h3 id=\"validating-and-correcting-sqlqueries\">Validating and Correcting SQL¬†Queries</h3>\n<p>Once the LLM generated SQL queries, the next step was validation. By running the queries on a SQLite database, I could determine whether the queries were syntactically correct and returned meaningful results. If the query was incorrect, the model reflected on it to generate a corrected version.</p>\n<h3 id=\"example-inpython-1\">Example in¬†Python:</h3>\n<p>import sqlite3<br>\nimport pandas as pd<br>\n# Validate the generated SQL query<br>\nengine = sqlite3.connect(‚Äù./nba_roster.db‚Äù)<br>\ntry:<br>\ndf = pd.read_sql(result[‚Äòsqlite_query‚Äô], con=engine)<br>\nprint(df)<br>\nexcept Exception as e:<br>\nprint(f‚ÄùError in query: {e}‚Äù)</p>\n<p>This process ensures that the queries generated by the model are not only syntactically correct but also return meaningful results. Automating this validation can help reduce errors and improve the efficiency of data teams.</p>\n<h3 id=\"fine-tuning-themodel\">Fine-Tuning the¬†Model</h3>\n<p>One of the most exciting parts of the course was learning how to fine-tune the LLM to improve its performance in SQL query generation. Fine-tuning involved training the model with a custom dataset that included specific questions and their corresponding correct SQL queries. This process allowed the model to adapt to the particular nuances of SQL queries and improve its ability to generate accurate results.</p>\n<p>At <strong>CodeIA.cl</strong>, we can help businesses customize LLMs to their specific data needs. Whether it‚Äôs training models to generate SQL queries, optimize data pipelines, or automate complex workflows, our expertise in AI can accelerate the development of tailored solutions that meet your unique business challenges.</p>\n<h3 id=\"evaluating-model-performance\">Evaluating Model Performance</h3>\n<p>Evaluation is crucial when working with AI models. In this course, I learned how to evaluate the LLM‚Äôs performance by comparing its generated queries to a reference dataset (gold standard). This evaluation process helps in identifying areas where the model needs further improvement.</p>\n<h3 id=\"example-of-evaluation\">Example of Evaluation:</h3>\n<p># Example of evaluation - comparing generated SQL with reference SQL<br>\nreference_sql = ‚ÄúSELECT ‚Ä¶ (your gold standard query)‚Äú<br>\ntry:<br>\nref_df = pd.read_sql(reference_sql, con=engine)<br>\nprint(ref_df)<br>\nexcept Exception as e:<br>\nprint(f‚ÄùError in reference query: {e}‚Äù)</p>\n<p>At <strong>CodeIA.cl</strong>, we ensure that AI models perform optimally through rigorous testing and evaluation. We offer services to fine-tune models, compare their outputs with gold-standard datasets, and implement continuous learning systems to keep models up-to-date with evolving data needs.</p>\n<h3 id=\"filtering-and-cleaning-thedataset\">Filtering and Cleaning the¬†Dataset</h3>\n<p>To ensure the quality of the dataset used for fine-tuning and evaluation, I applied filtering techniques to remove invalid queries, queries that returned empty results, or queries that contained errors. This step was crucial for maintaining the integrity of the training data and ensuring that the model learned from accurate and relevant examples.</p>\n<h3 id=\"how-codeiacl-can-support-yourbusiness\">How CodeIA.cl Can Support Your¬†Business</h3>\n<p>At <strong>CodeIA.cl</strong>, we specialize in helping businesses harness the power of AI and LLMs to solve complex challenges. Our services include:</p>\n<ul>\n<li><strong>Custom Model Development:</strong> We develop and fine-tune AI models tailored to your specific needs, whether it‚Äôs SQL query automation, natural language processing, or other data-driven tasks.</li>\n<li><strong>Data Pipeline Optimization:</strong> We streamline and automate data workflows, ensuring that your data operations are efficient and error-free.</li>\n<li><strong>Continuous AI Support:</strong> We provide ongoing support to ensure that your AI models stay relevant as your business and data needs evolve.</li>\n</ul>\n<p>By partnering with <strong>CodeIA.cl</strong>, you can leverage cutting-edge AI technology to optimize your operations, reduce manual work, and unlock new opportunities for innovation.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>This course was a transformative experience that expanded my knowledge of how LLMs can be used to automate and optimize SQL query generation. By mastering the process of generating, validating, fine-tuning, and evaluating SQL queries with LLMs, I gained a deeper understanding of how AI can streamline data extraction tasks and improve accuracy in database management.</p>\n<p>At <strong>CodeIA.cl</strong>, we are ready to help your business adopt these advanced AI technologies. Whether you‚Äôre looking to automate SQL queries, optimize your data pipelines, or explore other AI-driven solutions, we have the expertise to guide you through the journey.</p>\n<p>If you‚Äôre interested in learning more about how <strong>CodeIA.cl</strong> can help your business, feel free to reach out. Let‚Äôs co-create innovative AI solutions together! üöÄ</p>\n<p>#AI #SQL #MachineLearning #DataScience #FineTuning #LLM #MetaLlama #CodeIA</p>\n<p>By <a href=\"https://medium.com/@devjaime\">Jaime Hern√°ndez</a> on <a href=\"https://medium.com/p/81f116646314\">August 16, 2024</a>.</p>\n<p><a href=\"https://medium.com/@devjaime/enhancing-sql-query-generation-with-large-language-models-llms-my-learning-journey-81f116646314\">Canonical link</a></p>\n<p>Exported from <a href=\"https://medium.com\">Medium</a> on March 15, 2025.</p>";

				const frontmatter = {"layout":"../../layouts/BlogLayout.astro","title":"Enhancing SQL Query Generation with Large Language Models (LLMs): My Learning Journey","description":"","tags":["code","SQL","LLMs"],"time":4,"featured":true,"timestamp":"2024-08-16T12:20:32-0300","filename":"2024-08-16_Enhancing-SQL-Query-Generation-with-Large-Language-Models--LLMs---My-Learning-Journey-81f116646314"};
				const file = "/Users/devjaime/Documents/devjaimeblog/src/pages/blog/2024-08-16_Enhancing-SQL-Query-Generation-with-Large-Language-Models--LLMs---My-Learning-Journey-81f116646314.md";
				const url = "/blog/2024-08-16_Enhancing-SQL-Query-Generation-with-Large-Language-Models--LLMs---My-Learning-Journey-81f116646314";
				function rawContent() {
					return "   \n                                        \n                                                                                              \n               \n                             \n       \n              \n                                     \n                                                                                                                         \n   \n\nEnhancing SQL Query Generation with Large Language Models (LLMs): My Learning Journey\n=====================================================================================\n\nIn the realm of AI and data science, SQL is an essential tool for extracting valuable insights from databases. As I explored new horizons‚Ä¶\n\n* * *\n\n### Enhancing SQL Query Generation with Large Language Models (LLMs): My Learning¬†Journey\n\n![](https://cdn-images-1.medium.com/max/800/1*Ee61cxklX1GAGpU0Oo8cdQ.png)\n\nIn the realm of AI and data science, SQL is an essential tool for extracting valuable insights from databases. As I explored new horizons in this field, I recently completed a course that taught me how to leverage Large Language Models (LLMs), specifically Meta-Llama-3‚Äì8B-Instruct, to generate, fine-tune, and validate SQL queries. This experience not only deepened my understanding of AI‚Äôs potential in query automation but also highlighted the power of prompt engineering and fine-tuning to achieve better results. Here‚Äôs a breakdown of what I learned, including practical examples and how CodeIA.cl can help businesses adopt these technologies.\n\n### Generating SQL Queries with¬†LLMs\n\nOne of the core concepts I explored was using LLMs to generate SQL queries based on provided schemas and example queries. By crafting customized prompts, I was able to instruct the model to generate relevant SQL queries in response to specific questions, such as ‚ÄúWhat is the average weight in the NBA?‚Äù\n\n### Example in¬†Python:\n\nfrom dotenv import load\\_dotenv  \nimport lamini  \nfrom util.get\\_schema import get\\_schema  \nfrom util.make\\_llama\\_3\\_prompt import make\\_llama\\_3\\_prompt  \nload\\_dotenv()   \\# Load environment variables  \nllm = lamini.Lamini(model\\_name=\"meta-llama/Meta-Llama-3-8B-Instruct\")  \n\\# Define the schema and the question  \nsystem = f\"\"\"You are an NBA analyst with 15 years of experience writing complex SQL queries.  \nConsider the nba\\_roster table with the following schema:  \n{get\\_schema()}\"\"\"  \nquestion = \"What is the average weight in the NBA?\"  \nprompt = make\\_llama\\_3\\_prompt(question, system)  \n\\# Generate the SQL query  \nresult = llm.generate(prompt, output\\_type={\"sqlite\\_query\": \"str\"}, max\\_new\\_tokens=200)  \nprint(result\\['sqlite\\_query'\\])\n\nIn this example, the model generates an SQL query based on the schema of an NBA roster and the provided question. This type of automation can significantly speed up data extraction tasks, making it easier for analysts to focus on insights rather than writing complex queries manually.\n\n### Validating and Correcting SQL¬†Queries\n\nOnce the LLM generated SQL queries, the next step was validation. By running the queries on a SQLite database, I could determine whether the queries were syntactically correct and returned meaningful results. If the query was incorrect, the model reflected on it to generate a corrected version.\n\n### Example in¬†Python:\n\nimport sqlite3  \nimport pandas as pd  \n\\# Validate the generated SQL query  \nengine = sqlite3.connect(\"./nba\\_roster.db\")  \ntry:  \n    df = pd.read\\_sql(result\\['sqlite\\_query'\\], con=engine)  \n    print(df)  \nexcept Exception as e:  \n    print(f\"Error in query: {e}\")\n\nThis process ensures that the queries generated by the model are not only syntactically correct but also return meaningful results. Automating this validation can help reduce errors and improve the efficiency of data teams.\n\n### Fine-Tuning the¬†Model\n\nOne of the most exciting parts of the course was learning how to fine-tune the LLM to improve its performance in SQL query generation. Fine-tuning involved training the model with a custom dataset that included specific questions and their corresponding correct SQL queries. This process allowed the model to adapt to the particular nuances of SQL queries and improve its ability to generate accurate results.\n\nAt **CodeIA.cl**, we can help businesses customize LLMs to their specific data needs. Whether it‚Äôs training models to generate SQL queries, optimize data pipelines, or automate complex workflows, our expertise in AI can accelerate the development of tailored solutions that meet your unique business challenges.\n\n### Evaluating Model Performance\n\nEvaluation is crucial when working with AI models. In this course, I learned how to evaluate the LLM‚Äôs performance by comparing its generated queries to a reference dataset (gold standard). This evaluation process helps in identifying areas where the model needs further improvement.\n\n### Example of Evaluation:\n\n\\# Example of evaluation - comparing generated SQL with reference SQL  \nreference\\_sql = \"SELECT ... (your gold standard query)\"  \ntry:  \n    ref\\_df = pd.read\\_sql(reference\\_sql, con=engine)  \n    print(ref\\_df)  \nexcept Exception as e:  \n    print(f\"Error in reference query: {e}\")\n\nAt **CodeIA.cl**, we ensure that AI models perform optimally through rigorous testing and evaluation. We offer services to fine-tune models, compare their outputs with gold-standard datasets, and implement continuous learning systems to keep models up-to-date with evolving data needs.\n\n### Filtering and Cleaning the¬†Dataset\n\nTo ensure the quality of the dataset used for fine-tuning and evaluation, I applied filtering techniques to remove invalid queries, queries that returned empty results, or queries that contained errors. This step was crucial for maintaining the integrity of the training data and ensuring that the model learned from accurate and relevant examples.\n\n### How CodeIA.cl Can Support Your¬†Business\n\nAt **CodeIA.cl**, we specialize in helping businesses harness the power of AI and LLMs to solve complex challenges. Our services include:\n\n*   **Custom Model Development:** We develop and fine-tune AI models tailored to your specific needs, whether it‚Äôs SQL query automation, natural language processing, or other data-driven tasks.\n*   **Data Pipeline Optimization:** We streamline and automate data workflows, ensuring that your data operations are efficient and error-free.\n*   **Continuous AI Support:** We provide ongoing support to ensure that your AI models stay relevant as your business and data needs evolve.\n\nBy partnering with **CodeIA.cl**, you can leverage cutting-edge AI technology to optimize your operations, reduce manual work, and unlock new opportunities for innovation.\n\n### Conclusion\n\nThis course was a transformative experience that expanded my knowledge of how LLMs can be used to automate and optimize SQL query generation. By mastering the process of generating, validating, fine-tuning, and evaluating SQL queries with LLMs, I gained a deeper understanding of how AI can streamline data extraction tasks and improve accuracy in database management.\n\nAt **CodeIA.cl**, we are ready to help your business adopt these advanced AI technologies. Whether you‚Äôre looking to automate SQL queries, optimize your data pipelines, or explore other AI-driven solutions, we have the expertise to guide you through the journey.\n\nIf you‚Äôre interested in learning more about how **CodeIA.cl** can help your business, feel free to reach out. Let‚Äôs co-create innovative AI solutions together! üöÄ\n\n#AI #SQL #MachineLearning #DataScience #FineTuning #LLM #MetaLlama #CodeIA\n\nBy [Jaime Hern√°ndez](https://medium.com/@devjaime) on [August 16, 2024](https://medium.com/p/81f116646314).\n\n[Canonical link](https://medium.com/@devjaime/enhancing-sql-query-generation-with-large-language-models-llms-my-learning-journey-81f116646314)\n\nExported from [Medium](https://medium.com) on March 15, 2025.";
				}
				async function compiledContent() {
					return await html();
				}
				function getHeadings() {
					return [{"depth":1,"slug":"enhancing-sql-query-generation-with-large-language-models-llms-my-learning-journey","text":"Enhancing SQL Query Generation with Large Language Models (LLMs): My Learning Journey"},{"depth":3,"slug":"enhancing-sql-query-generation-with-large-language-models-llms-my-learningjourney","text":"Enhancing SQL Query Generation with Large Language Models (LLMs): My Learning¬†Journey"},{"depth":3,"slug":"generating-sql-queries-withllms","text":"Generating SQL Queries with¬†LLMs"},{"depth":3,"slug":"example-inpython","text":"Example in¬†Python:"},{"depth":3,"slug":"validating-and-correcting-sqlqueries","text":"Validating and Correcting SQL¬†Queries"},{"depth":3,"slug":"example-inpython-1","text":"Example in¬†Python:"},{"depth":3,"slug":"fine-tuning-themodel","text":"Fine-Tuning the¬†Model"},{"depth":3,"slug":"evaluating-model-performance","text":"Evaluating Model Performance"},{"depth":3,"slug":"example-of-evaluation","text":"Example of Evaluation:"},{"depth":3,"slug":"filtering-and-cleaning-thedataset","text":"Filtering and Cleaning the¬†Dataset"},{"depth":3,"slug":"how-codeiacl-can-support-yourbusiness","text":"How CodeIA.cl Can Support Your¬†Business"},{"depth":3,"slug":"conclusion","text":"Conclusion"}];
				}

				const Content = createComponent((result, _props, slots) => {
					const { layout, ...content } = frontmatter;
					content.file = file;
					content.url = url;

					return renderTemplate`${renderComponent(result, 'Layout', $$BlogLayout, {
								file,
								url,
								content,
								frontmatter: content,
								headings: getHeadings(),
								rawContent,
								compiledContent,
								'server:root': true,
							}, {
								'default': () => renderTemplate`${unescapeHTML(html())}`
							})}`;
				});

const _page = /*#__PURE__*/Object.freeze(/*#__PURE__*/Object.defineProperty({
	__proto__: null,
	Content,
	compiledContent,
	default: Content,
	file,
	frontmatter,
	getHeadings,
	rawContent,
	url
}, Symbol.toStringTag, { value: 'Module' }));

export { _page as _ };
