/* empty css                                                                    */
import { d as createComponent, i as renderComponent, r as renderTemplate, u as unescapeHTML } from './astro/server_C7nAViGe.mjs';
import 'kleur/colors';
import { $ as $$BlogLayout } from './BlogLayout_COI89YL8.mjs';

const html = () => "<p>LiveKit es una plataforma moderna y de c√≥digo abierto que permite integrar video, audio y datos en tiempo real en tus aplicaciones. En este blog, te llevar√© por un recorrido t√©cnico desde su arquitectura interna hasta la creaci√≥n de un agente conversacional usando su sistema de agentes.</p>\n<h2 id=\"-qu√©-es-livekit-y-por-qu√©-importa\">üß± ¬øQu√© es LiveKit y por qu√© importa?</h2>\n<p>LiveKit nace como una alternativa potente y abierta a plataformas como Twilio o Agora, permitiendo tener control total sobre c√≥mo se enrutan y gestionan las comunicaciones en tiempo real.</p>\n<h3 id=\"caracter√≠sticas-destacadas\">Caracter√≠sticas destacadas:</h3>\n<ul>\n<li>Construido sobre WebRTC, el est√°ndar moderno para voz/video en tiempo real.</li>\n<li>C√≥digo abierto, con opci√≥n de autoalojamiento o LiveKit Cloud.</li>\n<li>SDKs para Web, iOS, Android, Flutter y Unity.</li>\n<li>Grabaci√≥n, transcodificaci√≥n, detecci√≥n de locutores, encriptaci√≥n, etc.</li>\n</ul>\n<p>LiveKit es utilizado en productos de alto tr√°fico como salas de reuniones, plataformas de aprendizaje remoto, sistemas de vigilancia inteligente y asistentes de voz.</p>\n<h2 id=\"-casos-de-uso-inspiradores\">üí° Casos de uso inspiradores</h2>\n<p>Aqu√≠ algunos ejemplos del potencial de LiveKit:</p>\n<h3 id=\"-1-videollamadas-educativas\">üé• 1. Videollamadas educativas</h3>\n<p>Construye una plataforma de aulas virtuales con control de c√°mara, chat y detecci√≥n autom√°tica de participaci√≥n.</p>\n<blockquote>\n<p>En este escenario, el sistema podr√≠a grabar y transcribir las clases autom√°ticamente usando STT (Speech to Text), permitiendo b√∫squedas posteriores o res√∫menes generados por un LLM.</p>\n</blockquote>\n<h3 id=\"-2-telesalud-con-ia\">üè• 2. Telesalud con IA</h3>\n<p>Doctores pueden atender pacientes remotamente mientras un agente de IA transcribe, interpreta y resume la conversaci√≥n m√©dica.</p>\n<blockquote>\n<p>Aqu√≠, el modelo STT convierte la conversaci√≥n en texto para almacenarla o enviarla a un LLM, el cual puede generar notas cl√≠nicas o alertas autom√°ticas si detecta condiciones relevantes.</p>\n</blockquote>\n<h3 id=\"-3-coordinadores-log√≠sticos-por-voz\">üßπ 3. Coordinadores log√≠sticos por voz</h3>\n<p>Como en el caso de FlipReady, un agente puede recibir comandos por voz del personal de limpieza, confirmar tareas, y enviar notificaciones a los administradores.</p>\n<blockquote>\n<p>El agente usa STT para entender los comandos y, si es necesario, consulta al LLM para validar informaci√≥n o responder preguntas frecuentes.</p>\n</blockquote>\n<h3 id=\"Ô∏è-4-avatares-conversacionales-en-metaverso\">üó£Ô∏è 4. Avatares conversacionales en metaverso</h3>\n<p>Integra avatares animados que reaccionan en tiempo real a lo que dicen los usuarios, con reconocimiento facial, voz, y generaci√≥n de respuestas naturales.</p>\n<blockquote>\n<p>En este caso se utilizan todos los m√≥dulos: STT para entender al usuario, LLM para generar una respuesta coherente, y TTS (Text to Speech) para responder con voz animada.</p>\n</blockquote>\n<h3 id=\"Ô∏è-5-frontend-inteligente-para-atenci√≥n-al-cliente\">üõéÔ∏è 5. Frontend inteligente para atenci√≥n al cliente</h3>\n<p>LiveKit puede actuar como la capa de comunicaci√≥n visual y auditiva para interfaces impulsadas por modelos como GPT, Claude o Mistral.</p>\n<blockquote>\n<p>Ideal para reemplazar formularios est√°ticos por experiencias conversacionales. El STT extrae la consulta, el LLM genera una soluci√≥n, y el TTS convierte todo en una respuesta fluida por voz.</p>\n</blockquote>\n<h2 id=\"-ejemplos-del-curso-agentes-con-livekit-explicativo-y-reflexivo\">üìò Ejemplos del Curso: Agentes con LiveKit (Explicativo y Reflexivo)</h2>\n<h3 id=\"componentes-de-un-agente-de-voz\">Componentes de un Agente de Voz</h3>\n<pre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"python\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dotenv </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_dotenv</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_ </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_dotenv(</span><span style=\"color:#FFAB70\">override</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#9ECBFF\">\"dlai-agent\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.setLevel(logging.</span><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> livekit </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> agents</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> livekit.agents </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Agent, AgentSession, JobContext, WorkerOptions, jupyter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> livekit.plugins </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    openai,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    elevenlabs,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    silero,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span></code></pre>\n<p><strong>¬øPor qu√© estas librer√≠as?</strong></p>\n<ul>\n<li><code>dotenv</code> permite cargar configuraciones sensibles desde un archivo <code>.env</code>.</li>\n<li><code>logging</code> esencial para monitorear el agente en producci√≥n.</li>\n<li><code>livekit.agents</code> estructura claramente el ciclo de vida del agente.</li>\n<li>Plugins (<code>openai</code>, <code>elevenlabs</code>, <code>silero</code>) proporcionan capacidades de generaci√≥n de respuestas y s√≠ntesis de voz.</li>\n</ul>\n<h3 id=\"ejecuci√≥n-del-agente\">Ejecuci√≥n del Agente</h3>\n<pre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"python\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MyAgent</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Agent</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> on_start</span><span style=\"color:#E1E4E8\">(self, session: AgentSession):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"ü§ñ Agente listo para recibir instrucciones de voz\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> on_audio</span><span style=\"color:#E1E4E8\">(self, audio: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">, context: JobContext):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> await</span><span style=\"color:#E1E4E8\"> context.transcribe(audio)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Texto reconocido:\"</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        reply </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> await</span><span style=\"color:#E1E4E8\"> context.ask_llm(text)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Respuesta del LLM:\"</span><span style=\"color:#E1E4E8\">, reply)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">        await</span><span style=\"color:#E1E4E8\"> context.speak(reply)</span></span></code></pre>\n<p><strong>Reflexi√≥n t√©cnica</strong>:</p>\n<p>Es fundamental entender cu√°ndo se usa cada m√≥dulo:</p>\n<ul>\n<li><strong>STT</strong> convierte audio en texto para ser procesado.</li>\n<li><strong>LLM</strong> genera respuestas basadas en contexto o consultas.</li>\n<li><strong>TTS</strong> convierte respuestas en voz.</li>\n</ul>\n<hr>\n<h2 id=\"-c√≥mo-construir-un-agente-con-livekit-paso-a-paso-repositorio-oficial\">üî® C√≥mo construir un agente con LiveKit paso a paso (Repositorio oficial)</h2>\n<p>El repositorio oficial de LiveKit Agents proporciona una base para construir agentes multimodales. Aqu√≠ el proceso paso a paso:</p>\n<h3 id=\"1-instalaci√≥n-de-dependencias\">1. Instalaci√≥n de dependencias</h3>\n<pre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\"><code><span class=\"line\"><span style=\"color:#B392F0\">pip</span><span style=\"color:#9ECBFF\"> install</span><span style=\"color:#79B8FF\"> -r</span><span style=\"color:#9ECBFF\"> requirements.txt</span></span></code></pre>\n<h3 id=\"2-estructura-del-agente-personalizado\">2. Estructura del agente personalizado</h3>\n<p>Implementa m√©todos espec√≠ficos como <code>on_start</code> y <code>on_audio</code>.</p>\n<h3 id=\"3-uso-del-jobcontext\">3. Uso del JobContext</h3>\n<p>Proporciona herramientas para STT, LLM y TTS.</p>\n<h3 id=\"4-configuraci√≥n-del-workeroptions\">4. Configuraci√≥n del WorkerOptions</h3>\n<p>Establece par√°metros y plugins necesarios para el agente.</p>\n<h3 id=\"5-despliegue-del-agente\">5. Despliegue del agente</h3>\n<pre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"python\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> livekit.agents </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Worker</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">worker </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Worker(</span><span style=\"color:#FFAB70\">options</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">opts)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">await</span><span style=\"color:#E1E4E8\"> worker.run()</span></span></code></pre>\n<h3 id=\"6-uso-en-jupyter-interactivo\">6. Uso en Jupyter interactivo</h3>\n<p>Facilita prototipos y demostraciones r√°pidas con <code>jupyter.run_agent_interactively()</code>.</p>\n<p>üëâ M√°s detalles y ejemplos en el <a href=\"https://github.com/livekit/agents\">repositorio oficial</a>.</p>";

				const frontmatter = {"layout":"../../layouts/BlogLayout.astro","title":"üß† LiveKit en Profundidad: Arquitectura, Conceptos Clave y C√≥mo Construir un Agente Conversacional","description":"Descubre c√≥mo funciona LiveKit, su arquitectura escalable basada en WebRTC, y aprende paso a paso c√≥mo construir un agente de voz con inteligencia artificial.","tags":["LiveKit","Agentes de Voz","WebRTC","Inteligencia Artificial","Python"],"time":20,"timestamp":"2025-05-25T00:00:00-0400","featured":true,"filename":"2025-05-25_livekit-agentes"};
				const file = "/Users/devjaime/Documents/devjaimeblog/src/pages/blog/2025-05-25_livekit-agentes.md";
				const url = "/blog/2025-05-25_livekit-agentes";
				function rawContent() {
					return "\n   \n                                        \n                                                                                                           \n                                                                                                                                                                             \n                                                                                  \n        \n                                     \n              \n                                      \n   \n\nLiveKit es una plataforma moderna y de c√≥digo abierto que permite integrar video, audio y datos en tiempo real en tus aplicaciones. En este blog, te llevar√© por un recorrido t√©cnico desde su arquitectura interna hasta la creaci√≥n de un agente conversacional usando su sistema de agentes.\n\n## üß± ¬øQu√© es LiveKit y por qu√© importa?\n\nLiveKit nace como una alternativa potente y abierta a plataformas como Twilio o Agora, permitiendo tener control total sobre c√≥mo se enrutan y gestionan las comunicaciones en tiempo real.\n\n### Caracter√≠sticas destacadas:\n- Construido sobre WebRTC, el est√°ndar moderno para voz/video en tiempo real.\n- C√≥digo abierto, con opci√≥n de autoalojamiento o LiveKit Cloud.\n- SDKs para Web, iOS, Android, Flutter y Unity.\n- Grabaci√≥n, transcodificaci√≥n, detecci√≥n de locutores, encriptaci√≥n, etc.\n\nLiveKit es utilizado en productos de alto tr√°fico como salas de reuniones, plataformas de aprendizaje remoto, sistemas de vigilancia inteligente y asistentes de voz.\n\n## üí° Casos de uso inspiradores\n\nAqu√≠ algunos ejemplos del potencial de LiveKit:\n\n### üé• 1. Videollamadas educativas\nConstruye una plataforma de aulas virtuales con control de c√°mara, chat y detecci√≥n autom√°tica de participaci√≥n. \n\n> En este escenario, el sistema podr√≠a grabar y transcribir las clases autom√°ticamente usando STT (Speech to Text), permitiendo b√∫squedas posteriores o res√∫menes generados por un LLM.\n\n### üè• 2. Telesalud con IA\nDoctores pueden atender pacientes remotamente mientras un agente de IA transcribe, interpreta y resume la conversaci√≥n m√©dica.\n\n> Aqu√≠, el modelo STT convierte la conversaci√≥n en texto para almacenarla o enviarla a un LLM, el cual puede generar notas cl√≠nicas o alertas autom√°ticas si detecta condiciones relevantes.\n\n### üßπ 3. Coordinadores log√≠sticos por voz\nComo en el caso de FlipReady, un agente puede recibir comandos por voz del personal de limpieza, confirmar tareas, y enviar notificaciones a los administradores.\n\n> El agente usa STT para entender los comandos y, si es necesario, consulta al LLM para validar informaci√≥n o responder preguntas frecuentes.\n\n### üó£Ô∏è 4. Avatares conversacionales en metaverso\nIntegra avatares animados que reaccionan en tiempo real a lo que dicen los usuarios, con reconocimiento facial, voz, y generaci√≥n de respuestas naturales.\n\n> En este caso se utilizan todos los m√≥dulos: STT para entender al usuario, LLM para generar una respuesta coherente, y TTS (Text to Speech) para responder con voz animada.\n\n### üõéÔ∏è 5. Frontend inteligente para atenci√≥n al cliente\nLiveKit puede actuar como la capa de comunicaci√≥n visual y auditiva para interfaces impulsadas por modelos como GPT, Claude o Mistral.\n\n> Ideal para reemplazar formularios est√°ticos por experiencias conversacionales. El STT extrae la consulta, el LLM genera una soluci√≥n, y el TTS convierte todo en una respuesta fluida por voz.\n\n## üìò Ejemplos del Curso: Agentes con LiveKit (Explicativo y Reflexivo)\n\n### Componentes de un Agente de Voz\n\n```python\nimport logging\nfrom dotenv import load_dotenv\n_ = load_dotenv(override=True)\n\nlogger = logging.getLogger(\"dlai-agent\")\nlogger.setLevel(logging.INFO)\n\nfrom livekit import agents\nfrom livekit.agents import Agent, AgentSession, JobContext, WorkerOptions, jupyter\nfrom livekit.plugins import (\n    openai,\n    elevenlabs,\n    silero,\n)\n```\n\n**¬øPor qu√© estas librer√≠as?**\n\n- `dotenv` permite cargar configuraciones sensibles desde un archivo `.env`.\n- `logging` esencial para monitorear el agente en producci√≥n.\n- `livekit.agents` estructura claramente el ciclo de vida del agente.\n- Plugins (`openai`, `elevenlabs`, `silero`) proporcionan capacidades de generaci√≥n de respuestas y s√≠ntesis de voz.\n\n### Ejecuci√≥n del Agente\n\n```python\nclass MyAgent(Agent):\n    async def on_start(self, session: AgentSession):\n        print(\"ü§ñ Agente listo para recibir instrucciones de voz\")\n\n    async def on_audio(self, audio: bytes, context: JobContext):\n        text = await context.transcribe(audio)\n        print(\"Texto reconocido:\", text)\n\n        reply = await context.ask_llm(text)\n        print(\"Respuesta del LLM:\", reply)\n\n        await context.speak(reply)\n```\n\n**Reflexi√≥n t√©cnica**:\n\nEs fundamental entender cu√°ndo se usa cada m√≥dulo:\n- **STT** convierte audio en texto para ser procesado.\n- **LLM** genera respuestas basadas en contexto o consultas.\n- **TTS** convierte respuestas en voz.\n\n\n---\n\n## üî® C√≥mo construir un agente con LiveKit paso a paso (Repositorio oficial)\n\nEl repositorio oficial de LiveKit Agents proporciona una base para construir agentes multimodales. Aqu√≠ el proceso paso a paso:\n\n### 1. Instalaci√≥n de dependencias\n```bash\npip install -r requirements.txt\n```\n\n### 2. Estructura del agente personalizado\nImplementa m√©todos espec√≠ficos como `on_start` y `on_audio`.\n\n### 3. Uso del JobContext\nProporciona herramientas para STT, LLM y TTS.\n\n### 4. Configuraci√≥n del WorkerOptions\nEstablece par√°metros y plugins necesarios para el agente.\n\n### 5. Despliegue del agente\n```python\nfrom livekit.agents import Worker\nworker = Worker(options=opts)\nawait worker.run()\n```\n\n### 6. Uso en Jupyter interactivo\nFacilita prototipos y demostraciones r√°pidas con `jupyter.run_agent_interactively()`.\n\nüëâ M√°s detalles y ejemplos en el [repositorio oficial](https://github.com/livekit/agents).\n";
				}
				async function compiledContent() {
					return await html();
				}
				function getHeadings() {
					return [{"depth":2,"slug":"-qu√©-es-livekit-y-por-qu√©-importa","text":"üß± ¬øQu√© es LiveKit y por qu√© importa?"},{"depth":3,"slug":"caracter√≠sticas-destacadas","text":"Caracter√≠sticas destacadas:"},{"depth":2,"slug":"-casos-de-uso-inspiradores","text":"üí° Casos de uso inspiradores"},{"depth":3,"slug":"-1-videollamadas-educativas","text":"üé• 1. Videollamadas educativas"},{"depth":3,"slug":"-2-telesalud-con-ia","text":"üè• 2. Telesalud con IA"},{"depth":3,"slug":"-3-coordinadores-log√≠sticos-por-voz","text":"üßπ 3. Coordinadores log√≠sticos por voz"},{"depth":3,"slug":"Ô∏è-4-avatares-conversacionales-en-metaverso","text":"üó£Ô∏è 4. Avatares conversacionales en metaverso"},{"depth":3,"slug":"Ô∏è-5-frontend-inteligente-para-atenci√≥n-al-cliente","text":"üõéÔ∏è 5. Frontend inteligente para atenci√≥n al cliente"},{"depth":2,"slug":"-ejemplos-del-curso-agentes-con-livekit-explicativo-y-reflexivo","text":"üìò Ejemplos del Curso: Agentes con LiveKit (Explicativo y Reflexivo)"},{"depth":3,"slug":"componentes-de-un-agente-de-voz","text":"Componentes de un Agente de Voz"},{"depth":3,"slug":"ejecuci√≥n-del-agente","text":"Ejecuci√≥n del Agente"},{"depth":2,"slug":"-c√≥mo-construir-un-agente-con-livekit-paso-a-paso-repositorio-oficial","text":"üî® C√≥mo construir un agente con LiveKit paso a paso (Repositorio oficial)"},{"depth":3,"slug":"1-instalaci√≥n-de-dependencias","text":"1. Instalaci√≥n de dependencias"},{"depth":3,"slug":"2-estructura-del-agente-personalizado","text":"2. Estructura del agente personalizado"},{"depth":3,"slug":"3-uso-del-jobcontext","text":"3. Uso del JobContext"},{"depth":3,"slug":"4-configuraci√≥n-del-workeroptions","text":"4. Configuraci√≥n del WorkerOptions"},{"depth":3,"slug":"5-despliegue-del-agente","text":"5. Despliegue del agente"},{"depth":3,"slug":"6-uso-en-jupyter-interactivo","text":"6. Uso en Jupyter interactivo"}];
				}

				const Content = createComponent((result, _props, slots) => {
					const { layout, ...content } = frontmatter;
					content.file = file;
					content.url = url;

					return renderTemplate`${renderComponent(result, 'Layout', $$BlogLayout, {
								file,
								url,
								content,
								frontmatter: content,
								headings: getHeadings(),
								rawContent,
								compiledContent,
								'server:root': true,
							}, {
								'default': () => renderTemplate`${unescapeHTML(html())}`
							})}`;
				});

const _page = /*#__PURE__*/Object.freeze(/*#__PURE__*/Object.defineProperty({
	__proto__: null,
	Content,
	compiledContent,
	default: Content,
	file,
	frontmatter,
	getHeadings,
	rawContent,
	url
}, Symbol.toStringTag, { value: 'Module' }));

export { _page as _ };
