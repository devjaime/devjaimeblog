/* empty css                                                                    */
import { d as createComponent, i as renderComponent, r as renderTemplate, u as unescapeHTML } from './astro/server_C7nAViGe.mjs';
import 'kleur/colors';
import { $ as $$BlogLayout } from './BlogLayout_COI89YL8.mjs';

const html = () => "<h1 id=\"mejorando-la-búsqueda-semántica-con-faiss-pinecone-y-langchain-un-caso-real-con-twitter\">Mejorando la Búsqueda Semántica con Faiss, Pinecone y LangChain: Un Caso Real con Twitter</h1>\n<p>En este blog exploramos cómo integrar Faiss y LangChain para construir un sistema de recuperación de información utilizando datos de…</p>\n<hr>\n<h3 id=\"mejorando-la-búsqueda-semántica-con-faiss-pinecone-y-langchain-un-caso-real-contwitter\"><strong>Mejorando la Búsqueda Semántica con Faiss, Pinecone y LangChain: Un Caso Real con Twitter</strong></h3>\n<p><img src=\"https://cdn-images-1.medium.com/max/800/1*BPRiSJ2pDe5wpx6QxNDutA.jpeg\" alt=\"\"></p>\n<p>En este blog exploramos cómo integrar <strong>Faiss</strong> y <strong>LangChain</strong> para construir un sistema de recuperación de información utilizando datos de Twitter. Además, discutimos cuándo es útil optar por <strong>Pinecone</strong>, una base de datos vectorial gestionada en la nube.</p>\n<h3 id=\"qué-esfaiss\">¿Qué es Faiss?</h3>\n<p>Faiss es una biblioteca de código abierto diseñada por Meta para la búsqueda eficiente de similitud entre vectores densos. Es muy utilizada en aplicaciones que requieren manejo de grandes cantidades de datos, como motores de recomendación, búsqueda de texto e imágenes.</p>\n<h3 id=\"qué-es-pinecone\">¿Qué es Pinecone?</h3>\n<p>Pinecone es una solución de base de datos vectorial en la nube, que permite indexar y buscar vectores sin preocuparte por la infraestructura. Pinecone ofrece escalabilidad sin tener que gestionar servidores, lo que lo hace ideal para aplicaciones en tiempo real y búsqueda de vectores en grandes volúmenes de datos.</p>\n<h3 id=\"caso-de-uso-recuperación-de-tweets-similares\">Caso de Uso: Recuperación de Tweets Similares</h3>\n<p>Este proyecto utiliza la API de Twitter para obtener tweets, generar sus embeddings con OpenAI y almacenarlos en un índice Faiss para realizar búsquedas semánticas. Aquí se muestra el paso a paso.</p>\n<h4 id=\"1-obtener-tweets-detwitter\">1. Obtener Tweets de Twitter</h4>\n<p>Primero, usamos la API de Twitter para obtener tweets basados en una búsqueda por palabra clave:</p>\n<p>import tweepy<br>\n# Autenticación en la API de Twitter<br>\nauth = tweepy.OAuthHandler(‘API_KEY’, ‘API_SECRET_KEY’)<br>\nauth.set_access_token(‘ACCESS_TOKEN’, ‘ACCESS_TOKEN_SECRET’)<br>\napi = tweepy.API(auth)<br>\n# Buscar tweets<br>\ntweets = api.search_tweets(q=“inteligencia artificial”, count=100)<br>\ndocs = [tweet.text for tweet in tweets]</p>\n<h4 id=\"2-generar-embeddings-conopenai\">2. Generar Embeddings con OpenAI</h4>\n<p>Usamos LangChain para generar los embeddings de cada tweet con OpenAI:</p>\n<p>from langchain.embeddings.openai import OpenAIEmbeddings<br>\nembeddings = OpenAIEmbeddings(openai_api_key=“TU_API_KEY”)</p>\n<h4 id=\"3-crear-índice-enfaiss\">3. Crear Índice en Faiss</h4>\n<p>Con los embeddings generados, almacenamos los vectores en un índice Faiss, lo que nos permite hacer búsquedas eficientes basadas en similitud.</p>\n<p>from langchain.vectorstores.faiss import FAISS<br>\n# Crear índice en Faiss<br>\nindex = FAISS.from_texts(docs, embeddings)</p>\n<h4 id=\"4-búsqueda-semántica-detweets\">4. Búsqueda Semántica de Tweets</h4>\n<p>Hacemos una búsqueda semántica para encontrar tweets similares al texto de una consulta.</p>\n<p>query = “últimos avances en inteligencia artificial”<br>\nresultados = index.similarity_search(query)<br>\nfor resultado in resultados:<br>\nprint(resultado)</p>\n<h3 id=\"cuándo-usar-faiss-o-pinecone\">¿Cuándo Usar Faiss o Pinecone?</h3>\n<ul>\n<li><strong>Faiss</strong> es ideal para proyectos que requieren procesamiento local con alto control sobre los recursos y optimización personalizada, especialmente si tienes acceso a GPUs.</li>\n<li><strong>Pinecone</strong>, por otro lado, es una opción potente para proyectos que necesitan escalabilidad inmediata y una base de datos gestionada en la nube, permitiendo realizar búsquedas en tiempo real sin preocuparte por la infraestructura.</li>\n</ul>\n<h4 id=\"integración-depinecone\">Integración de Pinecone</h4>\n<p>Si decides usar Pinecone en lugar de Faiss, puedes integrarlo fácilmente con LangChain y disfrutar de su almacenamiento en la nube para búsquedas semánticas rápidas y escalables.</p>\n<p>from langchain.vectorstores import Pinecone<br>\nimport pinecone<br>\n# Inicializar Pinecone<br>\npinecone.init(api_key=“TU_API_KEY”, environment=“us-west1-gcp”)<br>\n# Crear índice en Pinecone<br>\nindex_name = “my-index”<br>\npinecone.create_index(index_name, dimension=1536)<br>\nindex = pinecone.Index(index_name)<br>\n# Usar Pinecone en LangChain<br>\nvectorstore = Pinecone(index, embeddings.embed_query, “text”)</p>\n<h3 id=\"conclusión\">Conclusión</h3>\n<p>En este blog, exploramos cómo utilizar Faiss y Pinecone para mejorar la búsqueda semántica en aplicaciones que manejan grandes volúmenes de datos. Con <strong>Faiss</strong>, obtienes control y optimización local, mientras que con <strong>Pinecone</strong>, puedes delegar la infraestructura y concentrarte en la escalabilidad. En nuestro caso de uso, implementamos la búsqueda de tweets basados en inteligencia artificial, demostrando cómo estas tecnologías permiten hacer consultas rápidas y precisas.</p>\n<p>Ambas herramientas son potentes y te permiten adaptar tu solución según tus necesidades: <strong>control local con Faiss</strong> o <strong>escalabilidad gestionada con Pinecone</strong>.</p>\n<hr>\n<p>Para ver más ejemplos y el código completo, visita el <a href=\"https://github.com/devjaime/documentation-helper\">repositorio de GitHub</a>.</p>\n<p>By <a href=\"https://medium.com/@devjaime\">Jaime Hernández</a> on <a href=\"https://medium.com/p/d656afb87e7b\">September 23, 2024</a>.</p>\n<p><a href=\"https://medium.com/@devjaime/mejorando-la-b%C3%BAsqueda-sem%C3%A1ntica-con-faiss-pinecone-y-langchain-un-caso-real-con-twitter-d656afb87e7b\">Canonical link</a></p>\n<p>Exported from <a href=\"https://medium.com\">Medium</a> on March 15, 2025.</p>";

				const frontmatter = {"layout":"../../layouts/BlogLayout.astro","title":"Mejorando la Búsqueda Semántica con Faiss, Pinecone y LangChain: Un Caso Real con Twitter","description":"","tags":["code","Pinecone","LangChain"],"time":4,"featured":true,"timestamp":"2024-09-23T12:20:32-0300","filename":"2024-09-23_Mejorando-la-B-squeda-Sem-ntica-con-Faiss--Pinecone-y-LangChain--Un-Caso-Real-con-Twitter-d656afb87e7b"};
				const file = "/Users/devjaime/Documents/devjaimeblog/src/pages/blog/2024-09-23_Mejorando-la-B-squeda-Sem-ntica-con-Faiss--Pinecone-y-LangChain--Un-Caso-Real-con-Twitter-d656afb87e7b.md";
				const url = "/blog/2024-09-23_Mejorando-la-B-squeda-Sem-ntica-con-Faiss--Pinecone-y-LangChain--Un-Caso-Real-con-Twitter-d656afb87e7b";
				function rawContent() {
					return "   \n                                        \n                                                                                                  \n               \n                                       \n       \n              \n                                     \n                                                                                                                             \n   \n\nMejorando la Búsqueda Semántica con Faiss, Pinecone y LangChain: Un Caso Real con Twitter\n=========================================================================================\n\nEn este blog exploramos cómo integrar Faiss y LangChain para construir un sistema de recuperación de información utilizando datos de…\n\n* * *\n\n### **Mejorando la Búsqueda Semántica con Faiss, Pinecone y LangChain: Un Caso Real con Twitter**\n\n![](https://cdn-images-1.medium.com/max/800/1*BPRiSJ2pDe5wpx6QxNDutA.jpeg)\n\nEn este blog exploramos cómo integrar **Faiss** y **LangChain** para construir un sistema de recuperación de información utilizando datos de Twitter. Además, discutimos cuándo es útil optar por **Pinecone**, una base de datos vectorial gestionada en la nube.\n\n### ¿Qué es Faiss?\n\nFaiss es una biblioteca de código abierto diseñada por Meta para la búsqueda eficiente de similitud entre vectores densos. Es muy utilizada en aplicaciones que requieren manejo de grandes cantidades de datos, como motores de recomendación, búsqueda de texto e imágenes.\n\n### ¿Qué es Pinecone?\n\nPinecone es una solución de base de datos vectorial en la nube, que permite indexar y buscar vectores sin preocuparte por la infraestructura. Pinecone ofrece escalabilidad sin tener que gestionar servidores, lo que lo hace ideal para aplicaciones en tiempo real y búsqueda de vectores en grandes volúmenes de datos.\n\n### Caso de Uso: Recuperación de Tweets Similares\n\nEste proyecto utiliza la API de Twitter para obtener tweets, generar sus embeddings con OpenAI y almacenarlos en un índice Faiss para realizar búsquedas semánticas. Aquí se muestra el paso a paso.\n\n#### 1\\. Obtener Tweets de Twitter\n\nPrimero, usamos la API de Twitter para obtener tweets basados en una búsqueda por palabra clave:\n\nimport tweepy  \n\\# Autenticación en la API de Twitter  \nauth = tweepy.OAuthHandler('API\\_KEY', 'API\\_SECRET\\_KEY')  \nauth.set\\_access\\_token('ACCESS\\_TOKEN', 'ACCESS\\_TOKEN\\_SECRET')  \napi = tweepy.API(auth)  \n\\# Buscar tweets  \ntweets = api.search\\_tweets(q=\"inteligencia artificial\", count=100)  \ndocs = \\[tweet.text for tweet in tweets\\]\n\n#### 2\\. Generar Embeddings con OpenAI\n\nUsamos LangChain para generar los embeddings de cada tweet con OpenAI:\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings  \nembeddings = OpenAIEmbeddings(openai\\_api\\_key=\"TU\\_API\\_KEY\")\n\n#### 3\\. Crear Índice en Faiss\n\nCon los embeddings generados, almacenamos los vectores en un índice Faiss, lo que nos permite hacer búsquedas eficientes basadas en similitud.\n\nfrom langchain.vectorstores.faiss import FAISS  \n\\# Crear índice en Faiss  \nindex = FAISS.from\\_texts(docs, embeddings)\n\n#### 4\\. Búsqueda Semántica de Tweets\n\nHacemos una búsqueda semántica para encontrar tweets similares al texto de una consulta.\n\nquery = \"últimos avances en inteligencia artificial\"  \nresultados = index.similarity\\_search(query)  \nfor resultado in resultados:  \n    print(resultado)\n\n### ¿Cuándo Usar Faiss o Pinecone?\n\n*   **Faiss** es ideal para proyectos que requieren procesamiento local con alto control sobre los recursos y optimización personalizada, especialmente si tienes acceso a GPUs.\n*   **Pinecone**, por otro lado, es una opción potente para proyectos que necesitan escalabilidad inmediata y una base de datos gestionada en la nube, permitiendo realizar búsquedas en tiempo real sin preocuparte por la infraestructura.\n\n#### Integración de Pinecone\n\nSi decides usar Pinecone en lugar de Faiss, puedes integrarlo fácilmente con LangChain y disfrutar de su almacenamiento en la nube para búsquedas semánticas rápidas y escalables.\n\nfrom langchain.vectorstores import Pinecone  \nimport pinecone  \n\\# Inicializar Pinecone  \npinecone.init(api\\_key=\"TU\\_API\\_KEY\", environment=\"us-west1-gcp\")  \n\\# Crear índice en Pinecone  \nindex\\_name = \"my-index\"  \npinecone.create\\_index(index\\_name, dimension=1536)  \nindex = pinecone.Index(index\\_name)  \n\\# Usar Pinecone en LangChain  \nvectorstore = Pinecone(index, embeddings.embed\\_query, \"text\")\n\n### Conclusión\n\nEn este blog, exploramos cómo utilizar Faiss y Pinecone para mejorar la búsqueda semántica en aplicaciones que manejan grandes volúmenes de datos. Con **Faiss**, obtienes control y optimización local, mientras que con **Pinecone**, puedes delegar la infraestructura y concentrarte en la escalabilidad. En nuestro caso de uso, implementamos la búsqueda de tweets basados en inteligencia artificial, demostrando cómo estas tecnologías permiten hacer consultas rápidas y precisas.\n\nAmbas herramientas son potentes y te permiten adaptar tu solución según tus necesidades: **control local con Faiss** o **escalabilidad gestionada con Pinecone**.\n\n* * *\n\nPara ver más ejemplos y el código completo, visita el [repositorio de GitHub](https://github.com/devjaime/documentation-helper).\n\nBy [Jaime Hernández](https://medium.com/@devjaime) on [September 23, 2024](https://medium.com/p/d656afb87e7b).\n\n[Canonical link](https://medium.com/@devjaime/mejorando-la-b%C3%BAsqueda-sem%C3%A1ntica-con-faiss-pinecone-y-langchain-un-caso-real-con-twitter-d656afb87e7b)\n\nExported from [Medium](https://medium.com) on March 15, 2025.";
				}
				async function compiledContent() {
					return await html();
				}
				function getHeadings() {
					return [{"depth":1,"slug":"mejorando-la-búsqueda-semántica-con-faiss-pinecone-y-langchain-un-caso-real-con-twitter","text":"Mejorando la Búsqueda Semántica con Faiss, Pinecone y LangChain: Un Caso Real con Twitter"},{"depth":3,"slug":"mejorando-la-búsqueda-semántica-con-faiss-pinecone-y-langchain-un-caso-real-contwitter","text":"Mejorando la Búsqueda Semántica con Faiss, Pinecone y LangChain: Un Caso Real con Twitter"},{"depth":3,"slug":"qué-esfaiss","text":"¿Qué es Faiss?"},{"depth":3,"slug":"qué-es-pinecone","text":"¿Qué es Pinecone?"},{"depth":3,"slug":"caso-de-uso-recuperación-de-tweets-similares","text":"Caso de Uso: Recuperación de Tweets Similares"},{"depth":4,"slug":"1-obtener-tweets-detwitter","text":"1. Obtener Tweets de Twitter"},{"depth":4,"slug":"2-generar-embeddings-conopenai","text":"2. Generar Embeddings con OpenAI"},{"depth":4,"slug":"3-crear-índice-enfaiss","text":"3. Crear Índice en Faiss"},{"depth":4,"slug":"4-búsqueda-semántica-detweets","text":"4. Búsqueda Semántica de Tweets"},{"depth":3,"slug":"cuándo-usar-faiss-o-pinecone","text":"¿Cuándo Usar Faiss o Pinecone?"},{"depth":4,"slug":"integración-depinecone","text":"Integración de Pinecone"},{"depth":3,"slug":"conclusión","text":"Conclusión"}];
				}

				const Content = createComponent((result, _props, slots) => {
					const { layout, ...content } = frontmatter;
					content.file = file;
					content.url = url;

					return renderTemplate`${renderComponent(result, 'Layout', $$BlogLayout, {
								file,
								url,
								content,
								frontmatter: content,
								headings: getHeadings(),
								rawContent,
								compiledContent,
								'server:root': true,
							}, {
								'default': () => renderTemplate`${unescapeHTML(html())}`
							})}`;
				});

const _page = /*#__PURE__*/Object.freeze(/*#__PURE__*/Object.defineProperty({
	__proto__: null,
	Content,
	compiledContent,
	default: Content,
	file,
	frontmatter,
	getHeadings,
	rawContent,
	url
}, Symbol.toStringTag, { value: 'Module' }));

export { _page as _ };
